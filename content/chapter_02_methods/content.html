
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>&lt;no title&gt; &#8212; What kind of thing is a planet?</title>
    
  <link rel="stylesheet" href="../../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">What kind of thing is a planet?</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   What kind of thing is a planet?
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Front matter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../frontmatter/declaration.html">
   Declaration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../frontmatter/preamble.html">
   Preamble
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../frontmatter/abstract.html">
   Abstract
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../frontmatter/introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../frontmatter/acknowledgements.html">
   Acknowledgements
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Thesis
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_01_background/main.html">
   1. Review and Theory
  </a>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="intro.html">
   2. Chapter 2 - Tools and Methods
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="section1.html">
     2.1. The analytical toolkit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="section2.html">
     2.2. Numerical methods and the Underworld code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="section3.html">
     2.3. Suite-modelling, PlanetEngine and Everest
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="conclusion.html">
     2.4. Conclusion
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_03_everest/main.html">
   3. Everest
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_04_linear/main.html">
   4. Linear
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_05_viscoplastic/main.html">
   5. Viscoplastic
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_06_advanced/main.html">
   6. Advanced
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_07_discussion/main.html">
   7. Discussion
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../chapter_08_conclusion/main.html">
   8. Conclusion
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  End matter
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../references.html">
   References
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../../appendices/tables/main.html">
   Tables
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/chapter_02_methods/content.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/rsbyrne/thesis"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/rsbyrne/thesis/issues/new?title=Issue%20on%20page%20%2Fcontent/chapter_02_methods/content.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/rsbyrne/thesis/edit/main/book/content/chapter_02_methods/content.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="simple nav section-nav flex-column">
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p>RB_thesis_chapter2_draft1</p>
<p>Chapter 2 - Tools and Methods</p>
<p>Under the operating paradigm of our research program, the phenomena of tectonics as we know them are held to be the surface expressions of a global system of solid-state convection. Tectonics - literally the ‘construction’ of Earth and other planets’ surface geology on a global scale - will thus be studied by proxy of the mantle-scale circulations which are inferred to motivate it. Because the theory justifying this substitution mandates certain controls, assumptions, and simplifications which must be accommodated by our modelling methodology, we will discuss these matters a little here.</p>
<p>The analytical toolkit</p>
<p>Tectonics is known to us through its sensible processes of orogeny, seismicity, and volcanism. The energy available to carry out these permutations ultimately derives from the depletion of the thermal gradient of the Earth’s hot interior with space, mitigated to an uncertain degree by internal heat production via radiogenics, core despinning, and other means. Estimates of global heat flow vary from around 42 terawatts <span id="id1">[<a class="reference internal" href="../../references.html#id85">Dye, 2012</a>]</span> to upwards of 47 terawatts <span id="id2">[<a class="reference internal" href="../../references.html#id108">Davies and Davies, 2010</a>]</span>. Of this power, a mere 1% is thought to be necessary to account for all the geological activity witnessed on Earth <span id="id3">[<a class="reference internal" href="../../references.html#id88">Turcotte and Schubert, 2014</a>]</span>; if our Earth is a heat engine, it is a weak one.</p>
<p>The Nusselt number</p>
<p>A geodynamically rigid planet with Earth’s interior temperature would not be able to access even these modest energies: it would be trapped by its flat, linear conductive geotherm. That the planetary geotherm is evidently much greater than this is evidence that more kinetic processes are at work. The dimensionless temperature gradient is related to the Nusselt number or Nu, the ratio of the measured temperature gradient to the reference gradient, which is the purely conductive geotherm. It can be given in terms of the rate of change of the dimensionless potential temperature * with respect to dimensionless depth y*<span id="id4">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span>:</p>
<p>Nu = 1 + <em>y</em>S</p>
<p>Where xS indicates the average value across a surface. The asterisks indicate a non-dimensionalised quantity: this is a convention throughout the literature.</p>
<p>When dimensionless parameters are used - unit mantle thickness and unit temperature range - the conductive geotherm for a non-curved domain is exactly one. Hence, for square geometries, the dimensionless temperature gradient Nu does double-duty as the heat transfer efficiency: it is the factor by which heat transfer is greater than it could be due to conduction alone. For curved domains, where the outer length is greater than the inner length, the conductive geotherm is proportionately lesser as it is in a sense ‘stretched out’ across the circumference; letting f be the ratio of inner to outer lengths or radii, Nu in these cases diverges from the dimensionless temperature gradient by a factor of f for cylinders and f2for shells. Though harder to measure in practice than in theory, it is implicit that Earth’s Nusselt number must be much greater than one; it is sometimes cited in the order of 10 <span id="id5">[<a class="reference internal" href="../../references.html#id84">Tackley, 1996</a>]</span>, which is characteristic of laminar (sub-turbulent) flow <span id="id6">[<a class="reference internal" href="../../references.html#id83">White, 1984</a>]</span>.</p>
<p>The Prandtl, Grashof, Reynolds, and Rayleigh numbers</p>
<p>If conduction is insufficient to explain Earth’s geotherm, another process is implicated, and that is free convection - buoyancy-driven advection of heat. The relative effectiveness of convection is a product of two further dimensionless quantities. The Prandtl number Pr takes the ratio of momentum diffusivity and thermal diffusivity:</p>
<p>Pr  rr = r / rkr / (rcpr)</p>
<p>Where  is viscosity,  is density, k is thermal conductivity, cp is specific heat, and the r suffix indicates a choice of reference value for variable quantities. The Grashof number Gr, meanwhile, concerns the forces involved: it is the ratio of buoyancy to viscous drag. Without a sufficient Prandtl number, heat will escape from each parcel faster than the parcel itself can be transported by buoyancy; while, a low Grashof number would imply that the drag of the medium on each parcel is too great for buoyancy to overcome. These co-equal terms multiplied give us a third and final dimensionless quantity: the Rayleigh number Ra or ‘convective vigour’, which is more strictly interpreted as the ratio of the diffusive and convective time scales in the medium; i.e. Ra serves as the Peclet number for heat. For high values of Ra, convection is much more efficient than conduction for transporting heat, leading to high fluid velocities and flow regimes grading from sluggish to laminar to turbulent; while for low Ra, conduction dominates, and the material is largely or totally quiescent. Separating these two domains is an often empirically-obtained value, the Critical Rayleigh Number or Racr, which is connate to each fluid; Ra is sometimes given in terms of Racr as r = RaRacr. Values of Ra in most applications are subjectively extremely high, and usually represented in decimal orders of magnitude; for mantle materials as modelled forthwith, for example, the critical Ra can be shown to be somewhere between 103-104(Chapter 3). Although Racr is often obtained empirically, it can be derived from first principles, as will be shown.</p>
<p>The Rayleigh number is a powerful tool for interrogating the behaviours of convecting fluids; however, the correct parameterisation of such a heavily compound term is a nuanced affair. Several assumptions are commonly made in the context of mantle circulation which simplify matters at the cost of limiting the scope of validity.</p>
<p>The ‘infinite Prandtl’ assumption asserts that momentum diffusivity is incomparably greater than thermal diffusivity; i.e.:</p>
<p>r &gt;&gt; r</p>
<p>This is a defensible assumption for the Earth, where the estimated value of the Prandtl number is in fact around1023 <span id="id7">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span>. Implied by the above, but worth stating clearly, is that the Reynolds number of the system - the ratio of inertial to viscous forces - approaches zero: i.e. inertia is negligible, present velocity is independent of previous velocity, and turbulence is consequently impossible. (This follows because the thermal Peclet number, which is Ra, must be a product of Pr and Re; hence to be finite, its expression in terms of Pr and Re must cancel at the limit.)</p>
<p>The infinite Prandtl statement is often taken in tandem with the Boussinesq approximation, which neutralises all density-driven force terms which are not coefficients of gravity; in other words, the fluid is held to be incompressible:</p>
<p>ux + vy = 0</p>
<p>Where u and v connote horizontal and vertical velocity components respectively. The incompressibility assumption in two dimensions allows us to define a stream function (x, y):</p>
<p>u = y, v = -x</p>
<p>u =</p>
<p>Where u is the velocity vector and  is the familiar vector differential operator del. The stream function has many useful properties: lines of constant  are called streamlines and are everywhere parallel to the velocity vector at that point, and a difference in value between any two points defines the volumetric flux across a line connecting those points, or equivalently the advective flux when multiplied by density . (The absolute value of , however, is arbitrary and meaningless.)</p>
<p>In addition to the Boussinesq and infinite Prandtl assumptions, we may further assert that the gravity is always radial and varies only with depth, and that the fluid is inelastic, i.e. it has no stress memory. Together these several approximations hold wherever a dense, viscous fluid is subject to extreme pressures over relatively large spatio-temporal scales; hence they are held to be broadly appropriate for mantle problems, with some caveats.</p>
<p>With the aid of this toolkit of assumptions, together with the constitutive equations for conservation of mass and energy, it is possible to obtain velocity and pressure solutions for the otherwise insoluble Navier-Stokes equations: the conservation of momentum equations for viscous fluids. The derivation for mantle problems is canonical but lengthy; details can be found in the universally cited textbook literature on the topic <span id="id8">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>, <a class="reference internal" href="../../references.html#id88">Turcotte and Schubert, 2014</a>]</span>. One extremely useful product, however, is a family of robust parameterisations of the Rayleigh number for mantle convection. For a basally-heated system, the following holds:</p>
<p>Ra  rTrr2grb3cprrkr</p>
<p>Where  is the coefficient of thermal expansion and T is the temperature drop across the layer thickness b. It may be convenient instead to take the dynamic viscosity  =  instead; in which case:</p>
<p>Ra = Tgb3cpk</p>
<p>If the system is internally rather than basally heated - e.g. as a result of radiogenic heating from uniformly distributed isotopes across the mantle - the following instead obtains:</p>
<p>RaH   rr3grb5cprHrrkr2</p>
<p>Or, again, in terms of dynamic viscosity:</p>
<p>RaH = gHb5k</p>
<p>Where H is the heating in terms of power per mass. The expression for RaH relates to that for Ra by a factor of b2Hk, for reasons that will later become clear.</p>
<p>Of course, in reality, convection in the mantle is driven by both volumetric and basal heating. Unfortunately there is no incontrovertible derivations of a mixed-heating Rayleigh number, but one approach which has the virtue of simplicity takes the basally-heated Ra expression and adds a coefficient which may be interpreted as a non-dimensional H term:</p>
<p>H = H<em>b2kT</em></p>
<p>Where H* is the specific internal heating rate in W/kg and T* is the dimensionless temperature drop. Because the expression is derived as the quotient of RaH and Ra, the new H term may simply be provided as a coefficient of the basally-heated Ra derivation <span id="id9">[<a class="reference internal" href="../../references.html#id81">Moore, 2008</a>, <a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span>.</p>
<p>Because the Rayleigh number so expressed is equivalent to the coefficient of the buoyancy term, it is now clear why it is often simply dubbed ‘convective vigour’, as that is its primary effect. By parameterising the system in this way, the behaviour of seemingly distinct scenarios can be seen to be related through a common Rayleigh number; what’s more, a dimensionless treatment of the problem can be readily converted to a dimensionalised one by expanding the terms of Ra with their empirical or inferred values.</p>
<p>Linear stability analysis and the critical Rayleigh number</p>
<p>It was hitherto given that the critical Rayleigh number, below which convection is not possible, is typically obtained empirically. In fact, for simple cases such as this of planar basally-heated isoviscous flow, an expression for Racr due to arbitrary perturbations can be derived from the assumptions already held using linear stability analysis. First consider the state of a purely conducting system at thermal equilibrium:</p>
<p>Tc* = T0T1 - T0 + y*</p>
<p>Where Tc* is the dimensionless conductive temperature at dimensionless depth y*; i.e. there is a linear dependency of temperature and depth. Let us now impose a thermal anomaly ‘*, uncertain in wavelength and infinitesimal in amplitude:</p>
<p>‘*  T’* - Tc*</p>
<p>Where the starred notation indicates a non-dimensionalised parameter and the prime notation, here and henceforth, identifies a perturbation. The choice of  here relates to potential temperature, the quantity conserved along adiabats, which is what this perturbation will ultimately induce.</p>
<p>Before perturbation, the pressure gradient forces were defined solely by the hydrostatic pressure pc- the pressure field which is purely sufficient to counteract the force of gravity. After the introduction of the perturbation, but before the resultant perturbed state is realised, the pressure field is modified in two ways: by the buoyancy anomaly of the perturbation, but also by the contribution of the modified density of the parcel to pre-perturbative hydrostatic pressure. Taking this into account, we can define a true perturbation pressure ‘* as:</p>
<p>‘*  p’* - pc*</p>
<p>Where  p’* is the pressure deviation relative to the hydrostatic pressure.</p>
<p>What determines if this seed of chaos shall grow? Equivalently, we may ask which is faster - the growth of the anomaly, or the ambient restoring forces? The answer depends in part on the wavelength of the perturbation and in part on the overall convective vigour of the system; a very lengthy expansion <span id="id10">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span> reaches the sixth derivative before delivering the following relation:</p>
<p>Racr = 44*4  (4 + *2)3</p>
<p>Where * = b, the wavelength of perturbation equivalent to the original anomaly ‘* in the horizontal coordinate, expressed as a ratio of the layer thickness b, and Racr is what we came for: the ‘critical’ Rayleigh number above which perturbations of a given wavelength will grow more rapidly than they are diffused. The expression defines a curve through the space of Racr vs dimensionless wavenumber which has a single minimum: this is *cr, the wavelength of perturbation at which Racr is at its lowest. Perturbations near this critical wavelength will tend to grow the fastest, since, as it were, they experience the highest ‘local’ Rayleigh number. As it happens, this wavelength, and the minimum Ra it requires to grow, come to:</p>
<p>Racr, min = 2744   657.5, cr* = 22  2.828</p>
<p>At first glance it might seem that we have not truly answered the question of what defines the critical Rayleigh number for a convecting system as a whole, but rather only a contingent answer depending on wavelengths of perturbation. Consider, though, the significance of driving the Rayleigh number below the minimum critical value. This is equivalent to stating that no perturbations at all - not even the least stable ones - are able to grow quicker than the diffusive timescale. At the minimum critical value itself, it follows that only perturbations of 2 scale will grow; this value nonetheless serves adequately as  the Racr of the entire fluid, since a perturbation of such a wavelength will almost always arise at some point, if geometry permits.</p>
<p>Having determined the conditions under which the conductive planform becomes unstable, it behooves us to establish what the new stability criterion is which now the system seeks. Assuming that the fastest-growing perturbation will ultimately come to dominate all others, what we need is an expression for the velocity field in terms of  that we can solve for the critical wavelength cr <span id="id11">[<a class="reference internal" href="../../references.html#id76">Rayleigh, 1916</a>]</span>. First let us find the infinitesimal thermal anomaly in terms of perturbation wavelength, which must be a sinusoidal function in both y and x:</p>
<p>‘* = 0’<em>siny</em>sin2x**</p>
<p>Where  0’* is the first term of the Fourier expansion of ‘*and provides the wave amplitude, which is in fact arbitrary. We can now take the stream function  in terms of ‘ and substitute:</p>
<ul class="simple">
<li><p>= -<em>242</em>2 + 2 0’<em>sin(y</em>)cos(2x**)</p></li>
</ul>
<p>The contours of the stream function give the geometry of convection, which, for the critical  in two dimensions, takes the form of pairs of counter-rotating half-cells of aspect cr* / 2 = 2; in other words, the planform of convection at steady state for any basally-heated planar isoviscous system will tend to approach an aspect ratio with the approximate shape, in landscape, of the page this sentence is written on.</p>
<p>Boundary layer theory and the Ra-Nu scaling</p>
<p>The Rayleigh number by itself is a powerful tool for controlling and dissecting mantle convection models; but it would be better still if Ra, the chief input parameter of the convection, could be analytically related to the Nusselt number, the most important output parameter:</p>
<p>Nu  f(Ra)</p>
<p>Some function connects these quantities - but what? To answer this, it will be necessary to take what we have learned and delve into the uncertain world of boundary layers.</p>
<p>We have already established that when the Rayleigh number is supercritical, heat may be more rapidly transported by advection than by diffusion. The effect of the ensuing convection is to deflect this conductive geotherm  Tc* towards the steeper adiabatic geotherm: the path in temperature-pressure space along which the potential temperature  - that which a parcel would achieve if brought to a standard reference pressure without gaining or losing any heat - is effectively constant. As the abiabat approaches the system boundaries, a point of diminishing returns is reached, and conductive processes take precedence once more. These regions of conductivity are the convecting system’s boundary layers.</p>
<p>It is possible to obtain an expression for the thickness of these boundary layers by considering the linear stability of just the layers themselves. First, we must determine the rate at which the conductive layer expands. This is complicated in the first instance by the fact that the actual layer thickness itself is hard to define in a continuum. Traditionally, however, it has sufficed to define it as the domain across which the first ten percent of temperature is gained (or, equivalently for the basal layer, lost). Hence:</p>
<p>yT = 2Tt = 2.32t</p>
<p>Where yTis the boundary layer thickness, t is interpreted as the characteristic length scale of thermal diffusion , and T is the inverse error function of 0.1, a constant term approximately equal to 1.16.</p>
<p>As the boundary grows, so do the thermal buoyancy forces. The relevant Rayleigh number to parameterise the vigour of the incipient convection is taken over the boundary layer thickness itself, and hence swells as the layer swells:</p>
<p>RayT = TgyT3</p>
<p>Where  is the thermal expansivity and  is the dynamic viscosity . Now what we are interested in is what the thickness of the boundary layer will be when the Rayleigh number defined over it, RayT, is at its critical value. Below this value, convective disruption of the layer will not be possible, as any perturbations within the layer will be thermally diffused before they can grow; while above this value, convection is inevitable and the conductive profile of the layer cannot be sustained. The expression for this is the same as that for RayT, except that the temperature contrast T is half that of the system as a whole. This is because the dimensionless temperature change across the boundary layers goes from zero or unit at the outer edge to exactly 0.5 at the inner edge, where the boundary layers face the tepid conditions of the intracellular fluid; hence:</p>
<p>RayT, crit = TgyT, crit32</p>
<p>Whence it follows that:</p>
<p>yT = 2RaFgT13</p>
<p>Where RaF is coined to refer to the minimum critical Rayleigh number across the layer as defined when that layer is at the brink of collapse. At this point we might be tempted to define a general critical Rayleigh number for the layer alone by the same means we deduced one for the system as a whole previously. Unfortunately, the dynamic quality of the layer thickness yT poses one unknown too many. For a boundary layer that is developing through time, it is not guaranteed that an appropriate perturbation of the appropriate scale will emerge at the appropriate time, nor even that the geometry of the layer will ever be appropriate for such a perturbation to emerge in the first place. We have come as far as analytical methods can take us; to close the loop, it is necessary to obtain RaF empirically; and so we have:</p>
<p>yT = 807gT13</p>
<p>Where the value 807 is the empirical RaF for a free-slip surface <span id="id12">[<a class="reference internal" href="../../references.html#id78">Jaupart and Parsons, 1985</a>]</span>.</p>
<p>Now, because the thickness of a conductive layer is directly related to the thermal gradient across it, and thence to the Nusselt number Nu, while the right side contains the coefficients of the global Rayleigh number Ra, it finally becomes apparent what form the relationship between Nu and Ra should take:</p>
<p>Nu = 0.112Ra13, RaF = 807</p>
<p>Or more generally:</p>
<p>Nu  Ra,   13</p>
<p>That a scaling law of this form would obtain for two dimensionless flow constants such as these is not surprising; empirically, just such a relationship is in fact very widely attested <span id="id13">[<a class="reference internal" href="../../references.html#id80">Mckenzie <em>et al.</em>, 1974</a>, <a class="reference internal" href="../../references.html#id408">Solomatov, 1995</a>, <a class="reference internal" href="../../references.html#id79">Turcotte and Oxburgh, 1969</a>]</span>. Authors have differed, however, on the proper value of beta. Though the canonicity of the one-third value analytically derived above can scarcely be doubted, it is clear from the divergent results of numerous studies that, in practice, many more variables than we have accounted for enter the equation. Time-dependence, long-lived thermal heterogeneities, aspect ratio, internal heating, and countless other factors all have a part to play. The general form of the relationship, however, is not disputed.</p>
<p>Critical values for the internally-heated case</p>
<p>What we have deduced so far is valid only for planar domains with basal heating. It will be necessary to have mathematical tools for more sophisticated, Earth-like scenarios as well, as far as possible.</p>
<p>Consider a convecting system with constant and uniform internal heating. Basal heat will be disregarded. For this analysis it will be necessary to prescribe that the basal boundary is insulating; in other words, while the upper boundary retains a Dirichlet-type fixed temperature condition, the lower boundary must be a Neumann-type condition of heat flux zero. In such a system, we cannot rely on the difference of basal and surface temperature for our linear stability analysis. Instead:</p>
<p>Tr = b2Hk</p>
<p>Where, again, b is the layer thickness, H is the heating per mass,  is density, and k is conductivity. The new temperature scale is thus the factor by which temperature must be non-dimensionalised in this treatment. The conducting geotherm must take this into account, and can no longer be expected to be linear:</p>
<p>Tc* = T0Tr + y* - y*22</p>
<p>We now recall the Rayleigh number for internally heated convection, as given previously:</p>
<p>RaH = gHb5k</p>
<p>Which, together with the conductive geotherm Tc* provides:</p>
<p>dpc<em>dy</em> = -RaHTc*</p>
<p>I.e. the rate of change of the hydrostatic pressure with respect to depth. Unlike in the basally-heated case, the pressure here is given as dependent on the conductive temperature profile; previously, both temperature and hydrostatic pressure were necessarily linear with depth. From here the analysis proceeds much as in the basally-heated case , only to culminate in an insoluble ordinary differential equation <span id="id14">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span> from which only empirical data can recover us; such that ultimately:</p>
<p>RaH, cr, min = 867.8, cr* = 3.51</p>
<p><span id="id15">[<a class="reference internal" href="../../references.html#id77">Roberts, 1967</a>]</span></p>
<p>In other words, for the onset of convection in an internally-heated system with basal-insulating, surface-isothermal, free-slip boundaries, the critical Rayleigh number and characteristic wavelength are both a little more than one quarter greater than for the equivalent basally-heated case.</p>
<p>Chaos and attraction: approximate solutions to insoluble equations</p>
<p>The nature of convecting systems in practice ensures that even the simplest problems can be effectively or absolutely insoluble by analytical means. Though we will shortly outline methods for meeting these challenges experimentally, it is always unwise to go too far empirically whither mathematics cannot follow.</p>
<p>One means of probing beyond the insolubility barrier is to take an eigenmode expansion of the equations of state and discard all but the fewest number of terms which still support nonlinear interactions:</p>
<ul class="simple">
<li><p>= 4 + <em>22A()sin2x**sin(y</em>)</p></li>
<li><p>= 1rC()sin(2y*) - 2B()cos2x**sin(y*)</p></li>
</ul>
<p>Where  is again the stream function, x and y are coordinates,  is the featural wavelength, r is the Rayleigh number as a proportion of the critical value r = RaRacr, and A(), B(), and C() are time-dependent coefficients which are functions of , time non-dimensionalised by wavelength:</p>
<p>= 21 + 2<em>sin(y</em>)t*</p>
<p>The A, B, and C coefficients permit a powerful simplification in form. Selecting the appropriate equation from the infinite set contained in the eigenmode expansion <span id="id16">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span>, the following first-order differential equations can be obtained:</p>
<p>dAd = Pr(B - A)</p>
<p>dBd = rA - B - AC</p>
<p>dCd = -bc + AB</p>
<p>Where Pr is the Prandtl number, which must be kept finite for this analysis, though it may still be arbitrarily large; b represents:</p>
<p>b = 41 + 2*2</p>
<p>These three are the Lorenz Equations <span id="id17">[<a class="reference internal" href="../../references.html#id75">Lorenz, 1963</a>]</span>, for which solutions represent states of cellular 2D convection. Because they are severely truncated in form, their scope of validity is limited to low values of r. Nevertheless, they are conceptually extremely useful for characterising the macro-scale character of mantle convection, particularly approaching the point of criticality.</p>
<p>Of the three functions, A relates to the stream function, B the resultant temperature variations, and C a horizontally averaged temperature mode. Three obvious solutions to the system are:</p>
<p>A = B = C = 0</p>
<p>A = B = b(r - 1), C = r - 1</p>
<p>When r &lt; 1, the trivial first solution above describes the only stable steady-state solution and represents pure conduction, just as we would expect when Ra &lt; Racr. When r &gt; 1, this solution becomes unstable, and the only stable solutions become the positive and negative valencies of the second expression above, which represent clockwise and counterclockwise unicellular convection. The ‘choice’ of the system to devolve from the unbiased conductive solution to one of either the left- or right-biased convective solutions is termed a ‘pitchfork bifurcation’, the first of many we will encounter; its existence proves that mantle convection is chaotic.</p>
<p>The two convective solutions above have been shown to be stable - but are they necessarily steady? If we take our two primitive convective solutions further, a characteristic equation can be obtained from which we can derive the following special value of r:</p>
<p>r = Pr(Pr + b + 3)Pr - b - 1</p>
<p>When Pr &gt; b + 1, the above expression gives the value of r above which the two fundamental convective solutions are in fact not stable; in other words, it is the criterion for the instability of steady convection. It is also another kind of bifurcation - a Hopf bifurcation. Around a Hopf point, stable solutions are periodic and cyclical; solutions which cross the bifurcation are hence ‘captured’ by it and cycle through a finite set of states ad infinitum, until or unless those oscillations become great enough to tip a system into the zone of attraction of another Hopf point. Complex paths through phase space can thus be drawn which represent very high-order periodic solutions for the system that resist analytical description. These have been dubbed ‘strange attractors’; they are the iconic property of chaos theory.</p>
<p>So far, for the sake of argument, we have assumed a finite Prandtl number. This of course contravenes one of the foundational assumptions of our broader analysis. Before moving on, it behooves us to ask whether the chaotic behaviours observed in the Lorenz equations hold in the limit that Pr  .</p>
<p>This would imply, first of all, that A = B. Hence:</p>
<p>dAd = dBd = (r - 1)B - BC</p>
<p>dCd = -bC + B2</p>
<p>The fixed points of these new equations are the same as for the Lorenz equations, as is the conductive solution when A = B = C = 0, which as before is stable only for subcritical Ra; however, the convective solutions can be shown to be stable for all r &gt; 1. We might take this to imply that mantle convection cannot be chaotic after all. However, it must be recalled that the Lorenz analysis begins with severe truncation of non-linear terms. For higher-order truncations, it is evident that chaotic phases can exist <span id="id18">[<a class="reference internal" href="../../references.html#id89">Schubert <em>et al.</em>, 2001</a>]</span>, particularly at high Rayleigh numbers; what is not certain is whether, for a given degree of truncation and a given range of parameters, chaotic behaviours will manifest for a particular system. When we attempt to engage with the problem numerically and empirically through modelling, which is the purpose of this thesis, it will be seen that certain parameter bands are chaotic and time-dependent while others are not; ultimately it will be argued that such zones of chaos represent boundaries in a very high-dimensional phase space, and relate fundamentally to the nature and proper characterisation of tectonic modes.</p>
<p>Numerical methods and the Underworld code</p>
<p>When the font of analysis is exhausted, numerical solutions become indispensable. Though the construction of robust and accurate systems for the computation of mantle convection problems is far from trivial, many successful approaches have been developed over the years, each with its own advantages and limitations. For this thesis we adopt a finite-element approach, which has been extensively developed by many groups over more than a quarter of a century. In particular, we follow after Professor Moresi and colleagues, the developers of modelling codes including CITCOM, Ellipsis, and most lately Underworld <span id="id19">[<a class="reference internal" href="../../references.html#id71">Beucher <em>et al.</em>, 2019</a>, <a class="reference internal" href="../../references.html#id73">Farrington <em>et al.</em>, 2005</a>, <a class="reference internal" href="../../references.html#id72">May and Moresi, 2008</a>, <a class="reference internal" href="../../references.html#id552">Moresi <em>et al.</em>, 2003</a>, <a class="reference internal" href="../../references.html#id384">Moresi <em>et al.</em>, 2002</a>, <a class="reference internal" href="../../references.html#id383">Moresi <em>et al.</em>, 2007</a>, <a class="reference internal" href="../../references.html#id381">Moresi and Solomatov, 1995</a>, <a class="reference internal" href="../../references.html#id544">Moresi <em>et al.</em>, 1996</a>, <a class="reference internal" href="../../references.html#id385">Zhong <em>et al.</em>, 1998</a>]</span>.</p>
<p>Here we will discuss in broad terms the principles and infrastructure of our numerical modelling practice; particulars of model design and construction will be discussed in further chapters as relevance dictates.</p>
<p>Numerical methods</p>
<p>To take a numerical approach to mantle convection is to endeavour to iteratively solve the following system of equations, which are the Stokes, conservation, and advection-diffusion equations under the assumptions of incompressibility and infinite Prandtl number:</p>
<p>p - (D) = g</p>
<p>u = 0</p>
<p>Tt + uT = 2T + H</p>
<p>Where  is dynamic viscosity, D the strain rate tensor, p dynamic pressure,  the density anomaly, g the gravity vector, u the velocity vector, T temperature,  thermal diffusivity, t time, and H is a thermal source term, i.e. radiogenic heating. The first two equations together solve for velocity given buoyancy and viscosity without accounting for inertia (hence the lack of time-dependency), while the third equation governs determines the change in temperature at any given point after an infinitesimal time interval due to diffusion (the first term) and advection (the second). Temperature, being the only time-dependent quantity, is the only necessary variable of state for this system. It is further possible to construct the viscosity and diffusivity parameters as functions of space, time, temperature, velocity, et cetera, to achieve much more complex rheologies as desired; plastic, elastic, rigid, and insulating materials may all be implemented in this way, each with its own perils and caveats.</p>
<p>We have already established that the equations are generally insoluble; numerical methods are the only recourse. There are unavoidable tradeoffs in terms of time, memory, accuracy, flexibility, extensibility, and robustness associated with every numerical convection scheme. Many methods have been developed, including smooth particle hydrodynamics <span id="id20">[<a class="reference internal" href="../../references.html#id58">Monaghan, 2005</a>]</span> and discrete elements <span id="id21">[<a class="reference internal" href="../../references.html#id57">Cundall and Strack, 1980</a>]</span>. We employ a finite elements approach <span id="id22">[<a class="reference internal" href="../../references.html#id69">Hughes, 2012</a>]</span> in which the domain is divided into a finite network of cells (the ‘mesh’); all field values are hosted on the nodes, with integrals across elements approximated using Gauss quadrature <span id="id23">[<a class="reference internal" href="../../references.html#id61">Swarztrauber, 2003</a>]</span>.  Such an approach can of course yield only an approximation of what the original equations imply, but that approximation can be arbitrarily accurate depending on the fineness of discretisation. The question, then, is how coarse can the approximation be made without losing fidelity to the governing equations?</p>
<p>Computationally, the problem takes the form:</p>
<p>Au + Bp = f</p>
<p>BTu = 0</p>
<p>Where A is the known ‘stiffness’ matrix equivalent here to viscosity, u is a vector of unknown velocities, B is the discrete gradient operator, p contains the pressure unknowns, T indicates the transpose, and f is the known vector of body and boundary forces acting on the material. The objective is to solve for u as cheaply and reliably as possible; once a velocity solution is obtained, the system can be integrated in time and the cycle begins again. First, however, we require a solution for p. Multiplying both sides by BTA-1 and substituting for BTu = 0 we find:</p>
<p>BTA-1Bp = BTA-1f</p>
<p>Such a form exposes the pressure to solution by a Schur Complement method, at the cost of introducing the non-trivial A-1 operation, which is both heavy and costly. To avoid having to generate A-1, we may instead reproduce its effect using a Krylov Subspace method (KSP), wherein matrix-matrix products are resolved by decomposing them into iterative series of matrix-vector products, with each vector comprising the residual of the previous iteration until the residual is less than some nominated threshold: one very popular implementation of this concept is the Generalised Minimal Residual method, or GMRES <span id="id24">[<a class="reference internal" href="../../references.html#id62">Saad and Schultz, 1986</a>]</span>. Once a solution for p is obtained, we are free to solve for u through similar methods. The velocity solution can then be used to advect the temperature field and any other state variables using a standard Petrov-Galerkin scheme; for convection problems an ‘upwind’ variant can be used to avoid ‘wiggles’ between nodes <span id="id25">[<a class="reference internal" href="../../references.html#id59">Brooks and Hughes, 1982</a>]</span>. The actual time integral is carried out using a Runge-Kutta method for accuracy <span id="id26">[<a class="reference internal" href="../../references.html#id60">Hairer <em>et al.</em>, 2006</a>]</span> and is taken over a time interval chosen to be shorter than either the diffusive or the advective timescales across each element, i.e. the Courant condition <span id="id27">[<a class="reference internal" href="../../references.html#id63">Courant <em>et al.</em>, 1967</a>]</span>. Upon advection, the system is fully iterated in time and the process may be repeated, with the advantage that the pressure solution for the previous timestep can be retained to quicken the convergence of the subsequent step. Performance can be improved by incorporating preconditioners for each solve, which exploit a priori analytical insights into certain model configurations to constrain the solution space <span id="id28">[<a class="reference internal" href="../../references.html#id72">May and Moresi, 2008</a>]</span></p>
<p>This approach is accurate, robust and stable <span id="id29">[<a class="reference internal" href="../../references.html#id381">Moresi and Solomatov, 1995</a>]</span>. However, even in the best case scenario, the complexity of such a direct solution scales with the cube of the number of elements N3. To achieve a scaling behaviour closer to N, it is possible to drastically reduce the workload of the inner KSPs using an adaptive multi-grid approach. With this method, a solution is obtained first for a much coarser discretisation, and then corrected over successively finer meshes until the error is within a provided tolerance. In addition to speed and resilience, the multi-grid lends itself well to parallelisation, as the first-order global features of the model can be coordinated at the coarsest levels first, while finer local features captured in heavier arrays can be shared more judiciously, thus reducing communications overheads.</p>
<p>The method we have outlined is the product of decades of meticulous development and is known to be as reliable as it is quick. It has been comprehensively benchmarked across a wide range of rheologies and parameters, including models with extreme viscosity contrasts <span id="id30">[<a class="reference internal" href="../../references.html#id544">Moresi <em>et al.</em>, 1996</a>]</span>, elastic behaviour <span id="id31">[<a class="reference internal" href="../../references.html#id384">Moresi <em>et al.</em>, 2002</a>]</span>, and strain-localising mechanisms <span id="id32">[<a class="reference internal" href="../../references.html#id383">Moresi <em>et al.</em>, 2007</a>]</span>. It has been tested against physical laboratory experiments <span id="id33">[<a class="reference internal" href="../../references.html#id67">Mériaux <em>et al.</em>, 2018</a>]</span> and has been demonstrated to be robust and scalable up to thousands of parallel processes <span id="id34">[<a class="reference internal" href="../../references.html#id73">Farrington <em>et al.</em>, 2005</a>]</span>.</p>
<p>One shortcoming of the method we have described is the inappropriateness of the finite element mesh for preserving the geometries of integer-valued domains: for example deformation history, or the distribution of various material phases. Though there are ways of accommodating such features using mesh-based approaches, they tend to be cumbersome and inefficient. A superior approach is to incorporate Lagrangian particle swarms <span id="id35">[<a class="reference internal" href="../../references.html#id552">Moresi <em>et al.</em>, 2003</a>]</span>, which are able to carry much higher-resolution information than the mesh and can transport both real-valued data (e.g. temperature, viscosity) and integer-valued data (e.g. history, material identity), which mesh-based variables necessarily cannot. Swarms and their associated variables are advected according to the Stokes solution at the same time as the underlying mesh-based state variables. In turn, the Stokes solver calls for the swarms to be interpolated to the mesh if and when they become relevant to the solution. Interpolation can be costly and complicated for unstructured networks like particle swarms - prohibitively so if the node weightings must be recalculated with each timestep, as is the case for any advecting swarm - so it is important to carry out such an operation as infrequently and efficiently as possible. Gauss quadrature is the standard method, with simple nearest-neighbour evaluation to determine which elements own which particles. An alternative is to use a grid-based Voronoi algorithm <span id="id36">[<a class="reference internal" href="../../references.html#id65">Velić <em>et al.</em>, 2009</a>]</span> in which domains of control for each node are iteratively built out cell by cell; where two nodes lay claim to the same territory, the interpolation grid is refined, but only inside the conflicted cell; superfluous calculation is thereby minimised. Another strategy, particularly suited to the interpolation of very sparse swarms, uses a k-d tree to efficiently seek out the nearest particle from any given node. Regardless of interpolation style, the addition of particle swarms dramatically extends the utility of the finite element method.</p>
<p>The Underworld code</p>
<p>Particular software implementations of the methods outlined above have been developed over many computing generations, and several continue to co-exist today as part of a broad and branching family. The present state-of-the-art iteration is Underworld, which supports 2D, 3D, multigrid, and particle-in-cell features while also combining a powerful yet modular C-level infrastructure <span id="id37">[<a class="reference internal" href="../../references.html#id70">Quenette <em>et al.</em>, 2007</a>]</span> with a user-friendly, hyper-extensible Python-based API. Parallelisation is provided through MPI while the underlying solvers are implemented with PETSc. Though deeper layers of Underworld remain fully transparent and accessible, the Python layer is designed to encourage fluidity, creativity, and legibility in model building, providing encapsulated higher-level proxies for the multifarious underlying C assets while subtly encouraging a good modelling idiom in users. This has encouraged bespoke application development <span id="id38">[<a class="reference internal" href="../../references.html#id71">Beucher <em>et al.</em>, 2019</a>]</span> and the integration of geodynamics codes with other modelling packages <span id="id39">[<a class="reference internal" href="../../references.html#id66">Asten, 2018</a>]</span>.</p>
<p>The higher-level Underworld syntax fully exploits Python’s object-oriented idiom, encapsulating standard model features like meshes, swarms, variables, and solvers as independent instances of generalised classes. Each object corresponds to C-level structures which are in turn organised under the StGermain interoperability framework for computational modelling <span id="id40">[<a class="reference internal" href="../../references.html#id70">Quenette <em>et al.</em>, 2007</a>]</span>. The algorithmic firepower at the heart of the operation draws on the ubiquitous standard PETSc code for partial differential equations. By default the PETSc infrastructure is configured for robustness first, speed second; however, a range of options is exposed at the Python level to reconfigure the solvers as desired. The principles of encapsulation and localisation are carefully honoured in Underworld’s design, with use of global attributes minimised and namespace pollution strictly avoided. Consequently, deletion of obsolete references or ‘garbage collection’ operates mostly as a Python user would intuitively expect, so that in typical use cases it is rarely necessary to do more than the elementary due diligence to limit memory leaks. However, at the scales we have operated, unavoidable pointer entropy at the C-level has been found to proliferate to problematic levels at times. This has been mitigated by prudent reuse of already instantiated objects and by spawning the heaviest or lengthiest jobs in subprocesses to harness system-level garbage collection.</p>
<p>As accessible as the new tools are, care must still be taken to ensure an appropriately configured model, beginning with the choice of resolution. While temporal resolution, i.e. timestep size, is determined dynamically based on the prescribed tolerances, spatial resolution is the domain of the user. Overly fine elements are wasteful, while insufficiently fine elements will fail to faithfully discretise the underlying physics. As a rule of thumb, the spatial resolution in any given region should be half an order of magnitude finer at least than the smallest relevant model features in that vicinity. Of course, it is not always clear a priori what this scale will be. Boundary layer and plume theory can provide some information about featural dimensions at steady-state for simple rheologies; however, the sensitivity of mantle convection on potentially very small-scale instabilities means a resolution sufficient for steady-state may still bias the solution at other stages. The appropriate resolution can be sought empirically, by running a suite of progressively finer models until the point of diminishing returns is reached. In theory, a well-constructed model should converge with resolution in the limit that a discretised model becomes indistinguishable from a continuous one. If convergence does not occur within a computationally feasible envelope, the model may be presumed to be misconfigured in some deeper sense. Another means of determining the correct resolution is to run a single, very-high resolution test and conduct a power spectral analysis of the constituent fields; the shortest wavelength that contains information must dictate the spatial resolution. The nexus of Rayleigh number, featural thickness, and resolution places an upper bound on what parameters can realistically be tested in the context of a large suite-modelling experiment: although Ra approaching 109 are likely more appropriate for Earth whole-mantle convection <span id="id41">[<a class="reference internal" href="../../references.html#id339">Wolstencroft <em>et al.</em>, 2009</a>]</span>, most cases explored here are less than Ra = 107, which is amenable to resolutions in the order of 128 radial cells. If resources are particularly at a premium, static or even adaptive mesh refinement can be employed to concentrate resolution in areas where it is most needed. Unfortunately, it is a present shortcoming of Underworld that only quadrangular elements are supported, which limits grid refinement, though work toward supporting unstructured meshes is underway.</p>
<p>Underworld provides an interface to the underlying PETSc options, most notably the choice of inner solve method and tolerance. The default configuration for the solver is mg or ‘multigrid’, which is the method we have outlined here: this arguably provides the best balance of speed, robustness, scalability, flexibility, and parallelisability. Alternatives include mumps, ‘multifrontal massively parallel sparse direct solver’, and the ‘lower-upper method’ LU. Careful benchmarking is called for to choose the correct configuration, and optimum results cannot be assumed for the default configuration. Tolerances in particular should always be calibrated manually using convergence and power spectrum tests as outlined above. Excessively fine tolerances will needlessly delay solver convergence, while overly generous tolerances will introduce numerical noise into the solution. The chosen tolerances ultimately determine the uncertainty inherent to the model and should always be chosen with care and cited prominently.</p>
<p>Underworld in the annulus</p>
<p>Even with the gift of Moore’s law, fully three-dimensional models remain prohibitively expensive, particularly at sufficient resolutions. A two-dimensional annulus is a compromise that allows exploration of the influence of curvature without exponentially expanding the degrees of freedom. Although such a geometry cannot claim to reproduce Earth-like conditions as such, it is nonetheless appropriate for probing a wide range of mantle convection phenomena and continues to be widely used.</p>
<p>In Underworld, which at present uses Cartesian-type meshes, the annulus is constructed by deforming a rectilinear mesh around the origin such that the ratio of inner and outer radii f falls in the range 0  1, where f  1 approaches no curvature and f = 0 is a model with no core. When the aspect ratio and curvature are such that the two ends meet, those ends are made periodic and the result is a full annulus. For the whole Earth mantle, a ratio of f = 0.54 is appropriate, while for the upper mantle only f = 0.9 is more realistic. Naturally a full annulus of f = 1 is not possible, while severe solver complications manifest at f &lt; 0.2 due to the extreme deformation of the cells.</p>
<p>Our approach to the annulus has the advantage of robustness and simplicity. It is more amenable for the solvers and allows highly curved geometries without requiring a revision of any of the critical computational systems. However, it does have many shortcomings. Outer cells are stretched as inner cells are shortened, forcing a choice of either under- or over-resolution of one or other of the boundary layers. Boundary layer conditions for velocity must be defined according to unit vectors rather than simply Cartesian components; it then becomes necessary to rotate and unrotate the boundary vectors during each solver loop. In periodic cases with zero-shear upper and lower boundaries, we must also be careful to suppress any solid-body rotation that might emerge by calculating and subtracting any uniform global angular components from the velocity vector field. All of this takes time and CPU cycles.</p>
<p>For our annulus models, it has proven useful to write a bespoke mapping protocol to go from Cartesian to annular domains. The ‘box’ algorithm projects a standard unit square of x, y: (0, 1) onto each annulus or annular wedge such that Cartesian positions can be smoothly and swiftly evaluated in the box and vice versa. This provides a common frame of reference between rectilinear and curvilinear models of any scale and dimensions, with benefits for interoperability, usability, and visualisation. The procedure is both parallel-safe and parallel-efficient, and approaches C-level performance through careful, idiomatic usage of the NumPy interface. In theory it could be extended to any geometry which is a continuous mapping of a rectilinear mesh.</p>
<p>Suite-modelling, PlanetEngine and Everest</p>
<p>A marked advantage of Underworld over other codes is the exposure of the Python-level API, transforming a geodynamic numerical modelling code into a fully-featured platform for geodynamics-related application development. One product of this has been the UWGeodynamics application, which thoroughly streamlines the design and construction of fully-dimensionalised lithospheric-scale models for precise and accurate recreation of real-world scenarios <span id="id42">[<a class="reference internal" href="../../references.html#id71">Beucher <em>et al.</em>, 2019</a>]</span>, taking the already impressive ease-of-use of the standard Underworld interface and refining it still further for a particular use case.</p>
<p>Just as the particular challenges of lithospheric-scale modelling demanded and informed a bespoke tool, so have we found it necessary to invest in a unique software platform to support our idiosyncratic use case. The product has been two new pieces of research software, both open-source and freely available for the community to use, collaborate on, and iterate: PlanetEngine, an Underworld application for whole-mantle modelling in the annulus; and Everest, an HDF5 file protocol and associated tools for numerical exploration across potentially any field of science.</p>
<p>Here we will discuss the particular dimensions of the research problem at hand and describe the peculiar methodological framework and vocabulary we have developed in response. We will then provide an overview of the architectural solutions we have ventured and discuss some of the higher-level ‘big data’ methods which the new format now supports.</p>
<p>A conceptual meta-model for suite-modelling</p>
<p>What kind of thing is a planet? This, broadly stated, is the parent question from which all other research questions presented in this thesis derive. Though our immediate contribution must necessarily be limited and contingent, the methodologies we advance here reflect a genuine attempt to formulate a tractable framework that could eventually embrace a solution to this thorniest of planetary problems.</p>
<p>For this thesis, the term ‘suite-modelling’ is defined so as to encompass any modelling enterprise in which the primary research output derives from an analysis of the divergent behaviours of a series of models, rather than the particular outcomes of each. A model series of forty or four-hundred or four-thousand particular strike-slip zones done with the sole intent of, say, building a catalogue or database of tectonic scenarios, would not necessarily qualify as a suite-modelling exercise according to this rubrik. Conversely, a survey of only four strike-slips might qualify if the purpose was to attain a new general inference about strike-slips which emerges from and transcends the behaviour of any individual case. Suite-modelling in this sense is an outgrowth of, and shares common methods and objectives with, the sorts of first-order analytical approaches discussed earlier in this chapter. It is the pursuit of analytical truth by empirical means.</p>
<p>To understand the scope of this challenge it is instructive to consider perhaps the simplest possible example of a thermal convection model: a box with two insulated vertical walls and two horizontal walls of fixed temperature - one cooler, one warmer - containing some incompressible fluid whose nature we wish to scrutinise. Let us suppose the insulated walls are such that the temperature very rapidly equilibrates across each of the two walls, but only gradually equilibrates with the fluid, so that the wall temperature at any point is the spatiotemporal average (over certain wavelengths) of the fluid temperature adjacent to the wall. For this system, the only variables that we can control are the absolute temperatures of the two surfaces, or equivalently the gradient between them and a reference temperature, while the only variables we may observe are the temperatures of the two insulating walls.</p>
<p>Such an apparatus is the conceptual equivalent of a parameterised two-dimensional thermal convection model. From first principles, it can be seen to comprise:</p>
<p>A description or intention, which for this thought experiment is essentially just the previous paragraph. This we will term the ‘schema’ after Kant <span id="id43">[<a class="reference internal" href="../../references.html#id64">Kant, 1781</a>]</span>. There are infinitely many conceivable schemas which relate to each other through uncountably many dimensions, collectively defining a kind of ‘schematic space’ of which any particular schema is a vector.</p>
<p>The implementation, which involves a number of decisions which imperfectly reify the system into an usable form. These decisions have a first-order influence on the behaviour of the system; however, they are not properly a part of the system as such, and whatever influence they do have that does not directly serve the systemic intention is a limitation or shortcoming of the model which must be accounted for. The implementation is made up of some amount of irreducible experimental capital, like the box itself and the room it is held in, as well as some number of variable quantities, such as the thicknesses of the walls. The former we term the model ‘capital’, the latter the model ‘options’. Ideally, both the capital and the options of implementation disappear into the background, as when a sufficiently high-resolution model becomes indistinguishable from the equivalent analytical treatment. In practice, there is always a bleeding-over from implementation to conceptualisation; consequently, though the implementation details should ideally not enter into the final analytical formulations, they remain inseparable from those outcomes and - for the sake of completeness and reproducibility - must always travel with them as ‘metadata’.</p>
<p>It has two ‘system variables’: the temperatures of the opposing thermal walls. These variables can be assigned any of infinitely many values and must ultimately emerge in the final treatment as terms of any complete theorem for the model behaviour. Let us call these the ‘parameters’ of the model. The parameters are the degrees of freedom of the schema, so that the schema itself can be visualised as an infinite Cartesian plane with the parameters as axes: the ‘parameter space’. Upon this space, a specific ‘parameterisation’ can be represented as a vector, while a sequence of parameterisations is figurable as a curve. We will term any complete parameterisation a ‘case’ of the schema: a place in parameter space as indicated by a parameterisation vector. It is equivalent to the box from our thought experiment after the wall temperatures are set but before it is filled with fluid.</p>
<p>It has two ‘state variables’: the temperatures of the insulating walls, which are the finest metrics we are permitted to access for defining the interior behaviour. We will term these two variables the ‘configurables’ of the system, and any given set of values as a ‘configuration’ of the system defining a particular ‘state’ that the system can achieve. Just as the parameterisation was conceptualised as a vector through parameter space, so may we regard the configuration as a vector through ‘state-space’. Before configuration, a given system is everywhere and nowhere in state-space. In the example of our box experiment, the apparatus is ‘configured’ by pouring fluid into it; we may do this carefully, and hence know what configuration we are selecting, or carelessly, in which case we have no idea where in state-space we are placing the system. (One important consequence of the way we have described this concept is that all cases share the same state-space; a configuration in one case is equally conceivable in any other, allowing models to ‘move’ in case-space as readily as they move between states.)</p>
<p>According to this vocabulary, our box experiment can be described as follows. First we take the concept of the experiment and assemble the appropriate capital, carefully noting several model options whose quantities we have implicitly or explicitly decided along the way, such as the conductivity of the wall plates. We then ‘place’ our apparatus at a particular point in parameter space by setting the temperatures of the two thermal walls, thus choosing a fixed model case to explore. We then fill the box with fluid, thus ‘configuring’ it - at this stage we are of course careful to note the time.  At last, we step back from the apparatus and allow it to ‘iterate’, taking occasional measurements of the two state variables along the way. Eventually some termination condition is reached, and the experiment is ceased. Being good scientists, we again note the time before breaking for lunch.</p>
<p>What has unfolded here? The model has in effect travelled from one configuration in state-space to another. Along the way, the model has traced out a curve of intermediary configurations through state-space - a curve whose form we are made partially aware by way of our observations. Specifically, this curve is a parametric curve, i.e. a vector-valued function of time. We could imagine visualising it by plotting it against the two free wall temperatures, with the time since configuration represented by colour. Unlike any arbitrary curve which we could draw over state-space, this curve is very special: it is the unique, unbidden tendency of the model, arising solely from its own natural logic. Such a trajectory we will term a ‘traverse’.</p>
<p>What sort of knowledge do we hope to attain with such an exercise? If the model were taken to represent an interesting scenario in itself - for example, coolant flowing through an engine - then we have our answer: we wanted to know how such-and-such a thing would behave in such-and-such a situation, and now we know. But if our purpose is to understand the model itself, the outcome of any given experiment is not important. What we are really interested in is the traverse itself - and what the traverse tells us about the surface over which it extends.</p>
<p>We beg the indulgence of another thought experiment. This time, imagine we are on a causeway high above a dark and endless sea. We know that the surface of the sea is in motion, but we cannot perceive it directly. All we can say for sure is that the pattern of the currents is always the same. How can we ascertain what forces ultimately motivate the churning of the waters?</p>
<p>One option would be to follow the example of Winnie the Pooh <span id="id44">[<a class="reference internal" href="../../references.html#id56">Milne, 1988</a>]</span> and pepper the surface with little twigs. As each twig travels with the current, tracing out a single streamline, we carefully plot its position - northings vs eastings, say. It may be that we find that some twigs eventually come to rest over a downwelling, too buoyant to sink. Others may fall into ever-revolving loops, or conversely, reveal pathways that seem to continue endlessly. Over time we gradually build a sense of the overall nature of the current that is ever improving - and ever insufficient. For what is certain is that eventually we must stop casting sticks: it will never be possible to completely sample the infinite sea, nor even any region of that sea, even with infinite time - not to mention infinite twigs.</p>
<p>Let the sea represent state-space: the twigs are individual instances of our box model, with the eastings and northings representing the values of the two state variables; the paths traced by the twigs are individual traverses of a particular case of the model. We see now that a given case of a model is in fact a function that maps flow vectors to coordinates in state-space - what we shall hereafter call the ‘case function’ C:</p>
<p>C(c0, c1, … cn) =  u0, u1, … un = u</p>
<p>Where c stands for ‘configurable’, or variable of state, and u is the velocity in state-space. For the dark sea, the configurables are the eastings and northings of every point on the surface of the waters, while u is the flow vector at that point; for the box convection model, these are instead the temperatures of the non-thermal walls and the future temperature of those walls after time t.</p>
<p>A written statement of C would be equivalent to a complete analytical solution for the convection problem set out by this particular case. Obtaining such a statement would obviate any need to ever model that particular case of that particular schema again. Of course, such a scientific triumph is rarely achievable even in that small subset of cases where it is strictly possible. Even a partial solution over a limited interval would be conjectural at best: not only have we taken finite samples, but each sample was taken over a finite time interval - we would require a space-filling curve of observations, something only possible at infinity.</p>
<p>A more tractable approach would be to draw a ‘watershed’ diagram, ‘colouring’ - so to speak - each point in state-space according to the common limiting behaviours that models initialised at those points ultimately exhibit. For example, if it is observed that a particular minimum or loop of minima exists in state-space, one might characterise all instances culminating in that vicinity as belonging to a single ‘basin’ of the model. Somewhere in the unknown region between two basins must lie one or more ‘ridges’ and zero or more unobserved basins. By fitting curves through all such regions, one might produce a family of estimates of approximations of partial solutions to the case function: a contingent victory but still a valid one. Better still would be to design a sampling strategy around such an analysis, so that the ridges - chains of bifurcations in state-space - are aggressively sought rather than merely inferred.</p>
<p>Let us return to the dark sea, where we now observe that there has been a change in the wind. We repeat our experiment and find that the motion of the water is quite different from before. We infer that the flow is in fact controlled by two forcings. The first is constant: the shape of the sea bed we cannot perceive. The second is variable: the direction and strength of the wind. We resolve to track the wind with two further variables (either the wind vector components or the wind’s trend and magnitude) and commit ourselves to what now emerges as the true scientific challenge: the charting of the obscured sea floor by proxy of the ocean currents.</p>
<p>The two new ‘wind’ variables are the system variables of the dark sea. In the example of our box convection model, they correspond to the temperatures of the upper and lower thermal walls; while the unseen ocean floor corresponds to the enigmatic nature of the fluid inside the box, which it is our ultimate purpose to discover. The ranges of the system variables, as we have discussed, define ‘case-space’, the set of all case functions C. In this sense, the schema itself could now be thought of as a higher-order function - the ‘schema function’ S, whose outputs are case functions:</p>
<p>S(p0, p1, … pn)  C</p>
<p>Where p stands for ‘parameter’, the name we have chosen for system variables. Given the difficulties already discussed with respect to C, we must expect that a complete written expression for S will be either infeasible or impossible to obtain for all but the most trivial schema. Nevertheless, we are committed to bettering our knowledge of S by some means, for to understand it is to understand the schema as a whole. What we require is some means of collapsing the dimensionality of the problem.</p>
<p>One option would be to apply some sort of reduction to S:</p>
<p>SR = R  S</p>
<p>Where R is an operator that accepts the case functions C as returned by S and returns instead some statement or metric of C which summarises its first-order features. A familiar example of such a reduction would be the concept of ‘phase’ in the physical sciences. The phases of water - solid, liquid, gas, supercritical fluid, et cetera - are in effect statements regarding the form that water should be expected to take, at steady-state, given certain values of the two system variables, temperature and pressure: phase, in other words, is a reduction over the state-space of water. Extending this notion, a phase diagram can be thought of as a kind of reduced schema function, SR, which maps the degrees of freedom of S to the outputs of R.</p>
<p>A completely different approach to the same problem is represented by Hertzsprung-Russel (HR) diagram, which organises stars according to their colour and brightness. This is equivalent to taking randomly selected states from randomly selected traverses of randomly selected cases of the schema and plotting them according to some consistent reduction over each state - to wit, the average surface temperature (colour) and the stellar disc area (brightness). In effect, the HR plot is a kind of multi-case, discontinuously and stochastically sampled, shared state-space. The parameters of the HR schema are stellar mass, total internal energy, and relative elemental abundances, which - being a priori unknown - were not available as axes to organise the observations of stars. Instead these parameters, along with the missing time dimension and many other symmetries, became apparent a posteriori as clusters in shared state-space. (Principal Component Analysis is an example of how such clustering can be detected algorithmically, and for arbitrarily many dimensions to boot.) The HR diagram has understandably become a bellwether of astrophysics, as canonical as phase diagrams are for chemistry.</p>
<p>A third method has recently become available with the advent of modern machine learning techniques. ‘Page-ranking’ algorithms commonly work by representing each web page as a ~100,000-dimensional vector in lexical space, where the vector components are relative word frequencies. Network diagrams of semantic relatedness are constructed by determining distances through the resulting hypercube. These networks can then be tagged with metadata, equivalent to system variables or ‘parameters’ in our treatment, and used to study the evolution of online knowledge systems. Image recognition algorithms work on a similar principle but with the addition of intermediary layers. The ‘configurables’ in this instance are the RGB values of each pixel, while the ‘parameters’ are the categories associated with each image, usually by a human, i.e. ‘dog’, ‘cat’, ‘truck’, et cetera. Each case implies infinitely many configurations, yet there is evidently some symmetry in state-space for each case that uniquely implies its parameters. To detect these symmetries, the state- and case-spaces are interleaved with one or more ‘latent spaces’ of much lower dimension than either, revealing latent variables that map similar cases to potentially wildly unalike configurations. One shortcoming of this approach is that it is difficult to peer into these hidden layers to learn exactly how the algorithm knows what it appears to know. Lately, however, it has even become possible to ‘traverse’ these latent spaces - or, rather, to traverse shared state-space according to trajectories in latent space <span id="id45">[<a class="reference internal" href="../../references.html#id55">Mahendran and Vedaldi, 2015</a>]</span>. Such an approach can elucidate machine intuitions and potentially allow them to be captured in human-cognisable form.</p>
<p>Regardless of how it is achieved, the fundamental modus operandi of all these methods is the same: to uncover hidden symmetries that relate a multitude of superficially dissimilar effects to a small number of inferred causes. Minting an original vocabulary for this family of problems may help provoke novel collaborations between apparently disparate fields which share similar problems. We cannot hope to make much progress in isolation.</p>
<p>Suite-modelling for geodynamics: PlanetEngine and Everest</p>
<p>Having developed an expressive vocabulary for discussing suite-modelling problems, we now apply it to geodynamics. Our purpose is to constrain the nature of our problem, and determine what tools we require to successfully engage with it.</p>
<p>We begin with our intention, which is to ascertain the consequences of some rheological formulation through numerical modelling of mantle convection. This gives us our schema, which will be implemented through Underworld code. We have several options to consider: resolution, timestep size, tolerance. These we must carefully select according to the considerations discussed earlier. The parameters of our schema are manifold, and might include the Rayleigh number Ra, the heating term H, the degree of curvature f, the model aspect ratio A, the maximum viscosity contrast 0, the yielding coefficient , the thermal diffusivity , the thermal expansivity , the reference density , and more. Let us estimate the number of parameters to be in the order of 10 - this compares to only two in the examples presented thus far. At the configuration level, we have some number of state variables, beginning with the temperature field and possibly including the distribution of material phases, the stress history, and others. In two dimensions, each field has in the order of N2 degrees of freedom, where N is the resolution; if our resolution is in the order of 100, the total number of configurables will be in the order 104. This compares to the mere two configurables in both the box convection and ‘dark sea’ thought experiments before. Overall, the dimensions of the problem are clearly very much greater than before. Instead of two-dimensional planes describing the case- and state-spaces, these must now be represented by 10-dimensional and 100,000-dimensional hypercubes.</p>
<p>We are already aware of several methods with which to attack such a problem in post-analysis. What we have not discussed is the formidable theoretical, logistical, and organisational challenge of designing, commissioning, overseeing, and aggregating a suite-modelling campaign on this scale. Bespoke tools are called for; tools specific to geodynamics, as well as tools germane to suite-modelling in general. To answer these needs, we introduce PlanetEngine and Everest</p>
<p>PlanetEngine</p>
<p>PlanetEngine is a Python-based wrapper for the geodynamics code Underworld which specialises in dimensionless large-scale convection problems in Cartesian and cylindrical geometries. Its primary purpose is to provide successively higher-order objects that implement in code the suite-modelling idiom described above. Accordingly, PlanetEngine’s top-level classes include:</p>
<p>The ‘System’ class, which non-invasively and transparently wraps native Underworld models to provide an easy-to-use higher-level framework for essential model-wrangling operations, including methods for visualisation, initialisation, iteration, observation, checkpointing, loading, and more. The user is invited to flag system inputs as options, parameters, or configurables, which are then separately ‘stamped’ as metadata on all model outputs; apart from this, users are only expected to define ‘update’ and ‘iterate’ functions to enable all higher-level behaviours of the System interface. PlanetEngine systems correspond semantically to the ‘system’ notion introduced in our earlier conceptual model - that is, a system is a particular instance of a particular case, initialised at a particular point in state-space, with the equipped with the ability to integrate through time in accordance with the ‘flow’ of the case. PlanetEngine systems inherit from Everest Iterables (see next section), whence they derive most of their useful properties.</p>
<p>A family of abstractly-defined ‘conditions’, which may be either unique - suitable for initialising a model (e.g. a sinusoidal initial condition) - or non-unique - suitable for terminating them (e.g. a steady-state criterion). Conditions can be merged in various ways to create more complex conditions, for example overlaying noise over a conductive geotherm, or applying a horizontal perturbation after applying a vertical one. A special class of conditions allows model state variables to be initialised from the outputs of other models, even across different geometries. PlanetEngine conditions should be thought of as representing localities or regions in state-space, which may either be defined absolutely (i.e. with respect to the origin) or relatively (i.e. with respect to internal metrics, typically timestep or time index, of other systems). PlanetEngine conditions inherit from Everest Booleans and hence are valid inputs for Python ‘if’ statements and other boolean operations.</p>
<p>An ‘Observer’ class that makes and stores observations about Systems as they iterate through time. Observers are initialised with an observee System and a Condition object that determines when observations should be taken, e.g. every tenth step, or whenever average temperature exceeds a certain threshold. While it is a functionality of Systems to store their own state variables in full at certain user-defined intervals (i.e. checkpointing), it is the role of Observers to gather various derived datas, often of lower dimension than state-space, and typically at a much greater frequency than the checkpoint interval. PlanetEngine is designed to support extremely thorough runtime analyses while minimising any resulting impacts to iteration speed and memory usage. This is invaluable for very large model suites, where disk efficiency and sampling rate are priorities. PlanetEngine observers are Everest Producers but not Iterables in their own right; their internal reference count is incremented along with their associated system.</p>
<p>A ‘Traverse’ class which, when activated, builds a System from provided ingredients (schema, options, parameters, and configurables) and iterates it until a provided terminal condition is recognised. Observers may optionally be attached, which are ‘prompted’ to observe with every iteration (whether they do or not depends on their internal Condition). Traverses in PlanetEngine correspond directly to traverses in the conceptual model: they are journeys from a unique starting point to a non-unique end point according to the ineluctable logic of each case. PlanetEngine traverses are instances of the Everest Task class, hence their basic functionality is to do some ‘indelible work’ (work which is written to disk), which here involves taking at least one initial and one terminal checkpoint. This allows other traverses (or tasks generally) to pick up where the previous traverse left off.</p>
<p>The ‘Campaign’ class: the capstone functionality of PlanetEngine. Campaigns are a kind of Everest Container type which, when iterated, continually produce, execute, and destroy feasibly endless sequences of Traverses. Campaigns are configured to be operated by multiple unaffiliated processes, and even multiple separate devices, simultaneously. Hosted tasks are tracked using a ‘library card’ system which monitors which tasks are currently checked out by other processes, which have been returned complete, which incomplete, and which have been returned after having failed. Campaigns distinguish between failures due to systematic errors (e.g. unacceptable input parameters or misconfigured models) and failures due to extraneous circumstances (e.g. power outages); extensive use of context managers ensures resilience and minimises corruption, which can otherwise become critically problematic when suite populations grow beyond a user’s ability to individually curate them. Most importantly, Campaigns are designed to accept stopping and starting without complaint; resources may be attached and detached at will, or the campaign as a whole suspended for any length of time, without any logistical consequences: when the campaign is renewed, or new resources added, it is guaranteed to continue precisely from where it was before. Campaigns can be provided with static lists of jobs to loop through, but can also be given ‘smart’ assignments that react to model outcomes and change tack accordingly. For instance, a Campaign might be instructed to randomly sample case space until a bifurcation is encountered, then spawn new jobs parallel to that bifurcation to explore its extent. The potential of such a tool may be formidable.</p>
<p>In addition to its headline features, PlanetEngine provides a wide range of extended functionalities for basic Underworld objects. Some are being considered for incorporation into the main Underworld branch; others are more specialised for the particular use case of PlanetEngine. Highlights include:</p>
<p>Specialised visualisation options within and beyond Underworld’s built-in gLucifer interface. In particular, PlanetEngine provides a class that produces cheap, light, and consistent raster images and animations for any given Underworld data object at any given degree of detail - ideal for machine learning applications. PlanetEngine also offers a quickShow feature that aggressively searches for an appropriate visualisation strategy for any given input or inputs, automatically constructing projections and dummy variables as required, allowing for very rapid generation of figures. All PlanetEngine visualisations are wrapped in the Fig class, which handles disk operations, filenames, and other house-keeping matters.</p>
<p>A module that handles mappings between coordinate systems, especially between different annular domains, using a ‘box’ abstraction that normalises coordinates to a unit height/width/length volume, allowing - for instance - the evaluation of Underworld functions or data objects between multiple different meshes. This powers a workhorse copyField function that warps data between meshes to within a given tolerance; copyField can also be configured to tile, fade, or mirror spatially referenced data, allowing - for instance - a steady-state condition derived cheaply on a small-aspect coarse mesh to be tiled over a higher-aspect fine mesh.</p>
<p>An extensive toolbox of new Underworld ‘function’-type classes with a number of useful features, including lazy evaluation, optional lazy initialisation, optional incremental computation, optional memoisation, automated projection, automatic labelling, hash identification, and extended operator overloading. The new functions include dynamic one-dimensional variables (e.g. minima/maxima, integrals, average), region-limited operations, arbitrarily nested derivatives, stream functions, quantiles, vector operations, masks, normalisation functions, conditionals, filters, clips, and much more. Most of the new functions are built from standard Underworld functions and data types and are consequently robust and C-level efficient; all in turn inherit from the built-in Underworld function class and so may be used anywhere the native inventory is used; however, their design is particularly oriented towards and optimised for run-time analysis. All are tested parallel-safe and memory leak-free.</p>
<p>A series of analysis classes providing single-line invocation for common analytical operations, including Nusselt number, velocity root-mean-square, and vertical stress profile. Like PlanetEngine function objects, analysis objects are hashed and logged at initialisation to avoid needless duplication; they also store their observations locally and are configured to avoid redundant invocation. They export the Underworld function interface and so are safe to use inside Underworld systems: for example, one could define the yield stress in terms of some time-averaged function of the stress history by simply incorporating the appropriate PlanetEngine analyser.</p>
<p>A family of abstractly-defined ‘conditions’, both unique, suitable for initialising a model (e.g. a sinusoidal initial condition), and non-unique, suitable for terminating them (e.g. a steady-state criterion). Conditions can be merged in various ways to create more complex conditions, for example overlaying noise over a conductive geotherm, or applying a horizontal perturbation after applying a vertical one. A special class of conditions allows model state variables to be initialised from the outputs of other models, even across different geometries.</p>
<p>A system for attaching boundary and range assumptions directly to Underworld data objects, enabling automatic clipping and normalisation of hosted data whenever changes are detected.</p>
<p>Everest</p>
<p>Everest is a free, open-source Python package developed as a part of this thesis for the express purpose of organising and analysing massive suite-modelling campaigns. Fundamentally, it comprises two systems:</p>
<p>A library of Python classes which may be wrapped around user code to provide a high-level standardised interface for common suite-modelling operations.</p>
<p>A file format for HDF5 which provides disk correlates for objects inheriting from Everest and supports simultaneous and parallel access for any number of processes at once.</p>
<p>The core Everest class is the so-called ‘Built’. The general principle of the Built is to provide a framework that allows a complete working copy of the environment in which some data was produced to be recreated live, just as it originally was, using only some attached metadata. Modules which define a class that inherits from Built can be ‘anchored’ to an HDF5 file on disk, referred to as a ‘frame’; the class can then be loaded directly from the frame even if the original module is no longer present. Each Built is assigned a unique hashed identity based on the complete code of the module defining it, which in turn provides the name of the HDF ‘group’ that the object is filed under in the archive: a simple ‘word hash’ facility is provided that generates memorable English-pronouncable names based on each hash, for human convenience. If an instantiated Built is anchored, the parameters that initialised the instance are also saved and hashed: supported parameters for saving include all the standard Python and NumPy data types and containers, all objects that provide a Pickling interface (user-defined or otherwise), as well as any class or class instance that inherits from Built. The use of hashes ensures that even the slightest difference between two classes or instances will be recorded for posterity, so that large projects can never be corrupted by the introduction of small errors and new objects never overwrite, but instead coordinate with, any previously anchored objects which are identical; while the storing of ample metadata with each Built ensures complete reproducibility within the scope of the environment that Everest is made aware of. The use of hash identities alls means that all builts can be stored equally as top-level objects in the host frame without any negative organisational consequences: this is virtuous because an appropriate hierarchical structure to explore one particular scientific query may be entirely counterproductive even for an only slightly different query. Flat structures allow the most efficient organisational structure for each use-case to be mapped to the database on a case-by-case basis, without needlessly and perhaps irreversibly inflecting the database for one purpose alone.</p>
<p>Various subclasses to Built are provided which add further functionality. The Producer class adds support for producing and storing arbitrary data: outputs can be stored in memory, saved to the frame, or automatically configured to save at certain intervals depending on memory usage, clock time, or other factors; data can be sorted either in the order it is saved or in order of some provided index, in which case inadvertent duplication of entries is detected and prevented. The Iterator class, a kind of Cycler or callable Built, is designed to be inherited by intrinsically iterable models - for example, the mantle convection models discussed here which iterate through discrete time steps - and provides for saving and loading of states, ‘bouncing’ between states, iterating between step counts, and many other useful features. (An anchored Iterator is always aware of what states have previously been saved to the frame, even if they have been saved by completely disconnected processes, such that multiple devices can do work on the same model without clashing.) The State class provides for the definition of abstract conditions which can be evaluated with respect to other Builts; States can then be used to trigger Enactors, Conditions, Inquirers, and other objects, progressively supporting higher levels of coordination. The highest level of abstraction currently provided by Everest is the Task class, which permutes a given Cycler until a stipulated Condition is met; because the Task is itself both a Cycler and a Condition, it can be used as either input of another Task, allowing the construction of arbitrarily complex trees of tasks. Tasks also provide the very useful feature of being able to instantiate themselves as subprocesses, so that one process can serve as a master for many others: any errors are logged and returned to the master task where they are handled as per the user’s requirements. Carrying out a task in a subprocess also ensures that the slate is wiped clean for any future task: this is particularly important for memory management in large model suites, as the system-level garbage collectors are much more thorough than those provided at the Python or Cython levels.</p>
<p>Everest also provides bespoke Writer and Reader classes for the HDF5-based ‘frame’ to which Builts may optionally be anchored. The Writer automatically decides what sort of HDF5 object to create, and where, based on intuitive Python-level syntax: dictionaries are mapped to groups, for instance, while NumPy arrays are mapped to datasets or attributes as appropriate. The Writer also manages access to the frame using a lock file and a prime-number based ‘window of access’ protocol, so that simultaneous write operations never occur regardless of how many processes across how many devices may attempt access. The Reader, conversely, supports multiple simultaneous access through the new HDF5 single-write-simultaneous-read protocol. The Reader exports the Python ‘index’ and ‘slice’ syntaxes and is designed to provide fluid access to archived data no matter how hefty the frame becomes. It comes with its own search algorithm with wildcard support, allowing quick and easy filtering according to data type, Built type, hash identity, value, or any other data: search is recursive to a prescribed depth and is careful to appropriately manage loops where HDF5 links are present. It operates in two modes: ‘soft’, which returns summaries of query results, and ‘hard’, which returns all results and loads any pickled objects, Built classes, and Built instances which are included. This latter feature makes it very quick and easy to load, for example, one particular model out of thousands by referencing merely one or two of its input parameters, some faintly recalled property of its output data, and the hash ID of the associated type. Algorithmic access is of course also supported - iterating through models to produce a figure, for instance, or to conduct some test whose outcome could then be tagged to each model as metadata.</p>
<p>Finally, Everest also describes a ‘Scope’ class which is in effect an abstract statement about the range of ‘builts’, and the range of indices within the outputs of each built, for which some boolean statement evaluates true. Scopes are produced by indexing Readers with ‘Fetch’ requests, somewhat similar to SQL queries; the resultant ‘scope’ is instantiated with the metadata of the request that produced it, ensuring that all data travels with its full and proper context. Once instantiated, however, a scope is free to travel independent of the reader or indeed the frame over which it was defined: this is possible thanks to the use of unique hash identities for all Everest builts of equivalent type and initialisation profile. Once the desired Scope has been acquired, it can be used to ‘slice’ into a frame (once again through the Reader interface) to pull the indicated data in full. The Scope protocol allows easy and rapid aggregation of very large datasets across arbitrarily broad model suites. In tandem with standard disk-based analysis packages like Dask, they are intended to provide a pain-free solution for wrangling model data all the way up to the terabyte scale.</p>
<p>Conclusion</p>
<p>In this chapter we have discussed the theory of mantle convection; explained and justified our preferred numerical approach; introduced the software tools requisite for the job; and presented a detailed conceptual framework for our research methodology. Further and more detailed methods will be explained in future chapters as they become relevant. Although the challenge at hand is formidable - ever more evidently so as we progress - we hope we have demonstrated that the methodologies thus far outlined are tried, true, and fit for purpose. With equal parts ambition and caution, let us proceed.</p>
<p>References</p>
<p>Asten, Michael. 2018. “Education Matters: The ARC Basin GENESIS Hub–Connecting Solid Earth Evolution to Sedimentary Basins.” Preview 2018 (195): 27–32.</p>
<p>Beucher, Romain, Louis Moresi, Julian Giordani, John Mansour, Dan Sandiford, Rebecca Farrington, Luke Mondy, et al. 2019. “UWGeodynamics: A Teaching and Research Tool for Numerical Geodynamic Modelling.” Journal of Open Source Software 4 (36): 1136.</p>
<p>Brooks, Alexander N., and Thomas J. R. Hughes. 1982. “Streamline upwind/Petrov-Galerkin Formulations for Convection Dominated Flows with Particular Emphasis on the Incompressible Navier-Stokes Equations.” Computer Methods in Applied Mechanics and Engineering 32 (1): 199–259.</p>
<p>Courant, R., K. Friedrichs, and H. Lewy. 1967. “On the Partial Difference Equations of Mathematical Physics.” International Business Machines Corporation. Journal of Research and Development 11 (January): 215.</p>
<p>Cundall, P. A., and O. D. L. Strack. 1980. “Discussion: A Discrete Numerical Model for Granular Assemblies.” Géotechnique 30 (3): 331–36.</p>
<p>Davies, J. H., and D. R. Davies. 2010. “Earth’s Surface Heat Flux.” Solid Earth 1 (1): 5–24.</p>
<p>Dye, S. T. 2012. “Geoneutrinos and the Radioactive Power of the Earth.” Reviews of Geophysics  50 (3): 1.</p>
<p>Farrington, Rebecca, Louis Moresi, Steve Quenette, Robert Turnbull, and Patrick Sunter. 2005. “Geodynamic Benchmarking Tests in HPC.” In APAC Conference, Gold Coast, Australia. researchgate.net. https://www.researchgate.net/profile/Louis_Moresi/publication/293818794_Geodynamic_benchmarking_tests_in_HPC/links/56bbd33e08ae47fa3956c5cf.pdf.</p>
<p>Hairer, Ernst, Christian Lubich, and Michel Roche. 2006. The Numerical Solution of Differential-Algebraic Systems by Runge-Kutta Methods. Springer.</p>
<p>Hughes, Thomas J. R. 2012. The Finite Element Method: Linear Static and Dynamic Finite Element Analysis. Courier Corporation.</p>
<p>Jaupart, Claude, and Barry Parsons. 1985. “Convective Instabilities in a Variable Viscosity Fluid Cooled from above.” Physics of the Earth and Planetary Interiors 39 (1): 14–32.</p>
<p>Kant, Immanuel. 1781. Critique of Pure Reason. Cambridge University Press.</p>
<p>Lorenz, Edward N. 1963. “Deterministic Nonperiodic Flow.” Journal of the Atmospheric Sciences 20 (2): 130–41.</p>
<p>Mahendran, A., and A. Vedaldi. 2015. “Understanding Deep Image Representations by Inverting Them.” In 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5188–96.</p>
<p>May, Dave A., and Louis Moresi. 2008. “Preconditioned Iterative Methods for Stokes Flow Problems Arising in Computational Geodynamics.” Physics of the Earth and Planetary Interiors 171 (1): 33–47.</p>
<p>Mckenzie, D. P., J. M. Roberts, and N. O. Weiss. 1974. “Convection in the Earth’s Mantle: Towards a Numerical Simulation.” Journal of Fluid Mechanics 62 (3): 465–538.</p>
<p>Mériaux, Catherine A., Dave A. May, John Mansour, Zhihao Chen, and Owen Kaluza. 2018. “Benchmark of Three-Dimensional Numerical Models of Subduction against a Laboratory Experiment.” Physics of the Earth and Planetary Interiors 283 (October): 110–21.</p>
<p>Milne, Alan Alexander. 1988. The House at Pooh Corner. Dutton.</p>
<p>Monaghan, J. J. 2005. “Smoothed Particle Hydrodynamics.” Reports on Progress in Physics 68 (8): 1703.</p>
<p>Moore, William B. 2008. “Heat Transport in a Convecting Layer Heated from within and below.” Journal of Geophysical Research 113 (B11): 93.</p>
<p>Moresi, L., F. Dufour, and H. -B. Muuhlhaus. 2003. “A Lagrangian Integration Point Finite Element Method for Large Deformation Modeling of Viscoelastic Geomaterials.” Journal of Computational Physics 184: 476–97.</p>
<p>Moresi, L., F. Dufour, and H-B Muhlhaus. 2002. “Mantle Convection Modeling with Viscoelastic/Brittle Lithosphere: Numerical Methodology and Plate Tectonic Modeling.” Pure and Applied Geophysics, 2335.</p>
<p>Moresi, L. N., and V. S. Solomatov. 1995. “Numerical Investigation of 2D Convection with Extremely Large Viscosity Variations.” Physics of Fluids  7 (9). https://doi.org/10.1063/1.868465.</p>
<p>Moresi, Louis, Shijie Zhong, and Michael Gurnis. 1996. “The Accuracy of Finite Element Solutions of Stokes’ Flow with Strongly Varying Viscosity.” ELSEVIER Physics of the Earth and Planetary Interiors 97: 83–94.</p>
<p>Moresi, L., S. Quenette, V. Lemiale, C. Mériaux, B. Appelbe, and H-B Mühlhaus. 2007. “Computational Approaches to Studying Non-Linear Dynamics of the Crust and Mantle.” Physics of the Earth and Planetary Interiors 163 (1): 69–82.</p>
<p>Quenette, Steve, Louis Moresi, P. D. Sunter, and Bill F. Appelbe. 2007. “Explaining StGermain: An Aspect Oriented Environment for Building Extensible Computational Mechanics Modeling Software.” In Parallel and Distributed Processing Symposium, IPDPS 2007, 1–8.</p>
<p>Rayleigh, Lord. 1916. “LIX. On Convection Currents in a Horizontal Layer of Fluid, When the Higher Temperature Is on the under Side.” The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science 32 (192): 529–46.</p>
<p>Roberts, P. H. 1967. “Convection in Horizontal Layers with Internal Heat Generation. Theory.” Journal of Fluid Mechanics 30 (1): 33–49.</p>
<p>Saad, Youcef, and Martin H. Schultz. 1986. “GMRES: A Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems.” SIAM Journal on Scientific and Statistical Computing 7 (3): 856–69.</p>
<p>Schubert, Gerald, Donald L. Turcotte, and Peter Olson. 2001. Mantle Convection in the Earth and Planets. Cambridge University Press.</p>
<p>Solomatov, V. S. 1995. “Scaling of Temperature‐ and Stress‐dependent Viscosity Convection.” Physics of Fluids  7 (2): 266–74.</p>
<p>Swarztrauber, Paul N. 2003. “On Computing the Points and Weights for Gauss–Legendre Quadrature.” SIAM Journal of Scientific Computing 24 (3): 945–54.</p>
<p>Tackley, Paul J. 1996. “Effects of Strongly Variable Viscosity on Three-Dimensional Compressible Convection in Planetary Mantles.” Journal of Geophysical Research, Geophys. Monogr., 101 (B2): 3311–32.</p>
<p>Turcotte, D. L., and E. R. Oxburgh. 1969. “Convection in a Mantle with Variable Physical Properties.” Journal of Geophysical Research 74 (6): 1458–74.</p>
<p>Turcotte, Donald, and Gerald Schubert. 2014. “Geodynamics 3rd Edition | Structural Geology, Tectonics and Geodynamics.” Cambridge University Press. Cambridge University Press. June 19, 2014. http://www.cambridge.org/au/academic/subjects/earth-and-environmental-science/structural-geology-tectonics-and-geodynamics/geodynamics-3rd-edition?format=PB&amp;isbn=9780521186230#XLOAx0du5I2aQtTT.97.</p>
<p>Velić, Mirko, Dave May, and Louis Moresi. 2009. “A Fast Robust Algorithm for Computing Discrete Voronoi Diagrams.” Journal of Mathematical Modelling and Algorithms 8 (3): 343–55.</p>
<p>White, Frank M. 1984. Heat Transfer. Addison-Wesley Longman, Incorporated.</p>
<p>Wolstencroft, M., J. H. Davies, and D. R. Davies. 2009. “Nusselt–Rayleigh Number Scaling for Spherical Shell Earth Mantle Simulation up to a Rayleigh Number of 109.” Physics of the Earth and Planetary Interiors 176 (1): 132–41.</p>
<p>Zhong, Shijie, Michael Gurnis, and Louis Moresi. 1998. “Role of Faults, Nonlinear Rheology, and Viscosity Structure in Generating Plates from Instantaneous Mantle Flow Models.” Journal of Geophysical Research 103 (B7): 15255–68.</p>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/chapter_02_methods"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Rohan S. Byrne<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>
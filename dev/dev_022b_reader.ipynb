{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "geographic-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from collections import deque\n",
    "\n",
    "import h5py\n",
    "\n",
    "from aliases import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "occasional-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "osjoin = os.path.join\n",
    "def get_framepaths(datadir):\n",
    "    frmPaths = []\n",
    "    subDirs = [\n",
    "        p for p in (osjoin(datadir, n) for n in os.listdir(datadir))\n",
    "            if os.path.isdir(p)\n",
    "        ]\n",
    "    for subDir in subDirs:\n",
    "        frmPaths.extend(\n",
    "            osjoin(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "            )\n",
    "    return frmPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "seventh-powell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear2.frm'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename('/home/morpheus/workspace/mount/data/charon5/linear2.frm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "effective-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "osrel = os.path.relpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "wound-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'charon5/linear2.frm'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "osrel('/home/morpheus/workspace/mount/data/charon5/linear2.frm', datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "silver-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/morpheus/workspace/mount/data/charon5/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/plasticaspectfocus.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/plasticaspectfocus2.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/plasticaspect3.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda1/miranda1.frm',\n",
       " '/home/morpheus/workspace/mount/data/triton/MS98.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/plasticfull2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel3/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/charon3/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/charon2/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel5/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel5/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel5/plastic128.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel5/plasticaspectfocus4.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel5/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel4/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel4/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel4/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel4/plasticfull2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel4/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/pluto6old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/linear_backup.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/pluto6.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto6/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/pluto2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto2/pluto2old.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel2/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel2/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel2/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/charon4/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel1/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel1/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel1/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel1/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel1/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticffocus2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticffocus3.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticffocus.frm',\n",
       " '/home/morpheus/workspace/mount/data/umbriel6/plasticffocus3_old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/pluto1.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/plasticfull2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/pluto1old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/pluto1extra.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto1/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/charon1/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/pluto3old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/pluto3.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto3/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/pluto5.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/visctransition.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/pluto5old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto5/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda2/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda2/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda2/plasticfull.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda2/plasticannu.frm',\n",
       " '/home/morpheus/workspace/mount/data/miranda2/miranda2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/linear.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/pluto4.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/linear2.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/pluto4old.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/plasticheat.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/visctransition.frm',\n",
       " '/home/morpheus/workspace/mount/data/pluto4/plasticfull.frm']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_framepaths(datadir).index('/home/morpheus/workspace/mount/data/pluto1/.frm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ceramic-montreal",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Link iteration failed (bad heap free list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-899294d9e9f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pluto1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear2.frm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mKeysViewHDF5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeysView\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"<KeysViewHDF5 {}>\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/_collections_abc.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0mKeysView\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;34m\"\"\" Iterate over member names \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupIter.__next__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5l.pyx\u001b[0m in \u001b[0;36mh5py.h5l.LinkProxy.iterate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Link iteration failed (bad heap free list)"
     ]
    }
   ],
   "source": [
    "with h5py.File(os.path.join(datadir, 'pluto1', 'linear2.frm'), mode = 'r') as h5file:\n",
    "    print(h5file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-price",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "correct-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "frmPaths = []\n",
    "subDirs = [\n",
    "    p for p in (os.path.join(datadir, n) for n in os.listdir(datadir))\n",
    "        if os.path.isdir(p)\n",
    "    ]\n",
    "for subDir in subDirs:\n",
    "    frmPaths.extend(\n",
    "        os.path.join(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "western-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function h5py._hl.group.Group.copy(self, source, dest, name=None, shallow=False, expand_soft=False, expand_external=False, expand_refs=False, without_attrs=False)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.Group.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "considerable-queens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h5py._hl.group.ExternalLink"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.ExternalLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adopted-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'_string_foo'[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "likely-payroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      ".\n",
      "CPU times: user 8.33 s, sys: 433 ms, total: 8.76 s\n",
      "Wall time: 8.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "observees = dict()\n",
    "\n",
    "frmPath = frmPaths[0]\n",
    "with h5py.File('temp.frm', mode = 'w') as writefile:\n",
    "    with h5py.File(frmPath, mode = 'r') as readfile:\n",
    "        for i, (key, grp) in enumerate(readfile.items()):\n",
    "            if not i % 1000:\n",
    "                print('.')\n",
    "            try:\n",
    "                styp = grp.attrs['supertype'][8:]\n",
    "                if styp == 'System':\n",
    "                    wgrp = writefile.require_group(key)\n",
    "                    wgrp.attrs.update(grp.attrs)\n",
    "                    wgrp['inputs'] = h5py.ExternalLink(frmPath, os.path.join(key, 'inputs'))\n",
    "                elif styp == 'Observer':\n",
    "                    typ = grp.attrs['type'][8:]\n",
    "                    wgrp = writefile.require_group(grp['inputs'].attrs['observee'][7:])\n",
    "                    okey = typ.lower()\n",
    "                    if okey in wgrp:\n",
    "                        if len(wgrp[okey]['count']) > len(grp['outputs']['count']):\n",
    "                            continue\n",
    "                    wgrp[okey] = h5py.ExternalLink(frmPath, os.path.join(key, 'outputs'))\n",
    "            except (KeyError, RuntimeError):\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "visible-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = h5py.File('temp.frm', mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile['aabrspuugh-eistiopoov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "international-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "searching-heating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2917\n",
      "CPU times: user 4.93 ms, sys: 0 ns, total: 4.93 ms\n",
      "Wall time: 5.03 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with h5py.File('temp.frm', mode = 'r') as h5file:\n",
    "    print(len(h5file))\n",
    "    out = h5file['aabrspuugh-eistiopoov']['thermo']['Nu'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not __name__ == '__main__':\n",
    "#     raise RuntimeError\n",
    "\n",
    "# import os\n",
    "# from collections import deque\n",
    "\n",
    "# import h5py\n",
    "\n",
    "# from aliases import *\n",
    "\n",
    "# frmPaths = []\n",
    "# subDirs = [\n",
    "#     p for p in (os.path.join(datadir, n) for n in os.listdir(datadir))\n",
    "#         if os.path.isdir(p)\n",
    "#     ]\n",
    "# for subDir in subDirs:\n",
    "#     frmPaths.extend(\n",
    "#         os.path.join(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "#         )\n",
    "\n",
    "# with h5py.File(os.path.join(datadir, 'allout.frm'), mode = 'w') as writefile:\n",
    "#     for frmPath in frmPaths:\n",
    "#         print('-' * 10 + frmPath + '-' * 10)\n",
    "#         with h5py.File(frmPath, mode = 'r') as readfile:\n",
    "#             for i, (key, grp) in enumerate(readfile.items()):\n",
    "#                 grpkeys = grp.keys()\n",
    "#                 try:\n",
    "#                     if not grp.attrs['supertype'] == '_string_Observer':\n",
    "#                         continue\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#                 if not i % 1000:\n",
    "#                     print(key)\n",
    "#                 try:\n",
    "#                     readout = grp['outputs']\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#                 hashID = grp.attrs['hashID'][8:]\n",
    "#                 writegrp = writefile.require_group(hashID)\n",
    "#                 systemgrp = readfile[hashID]\n",
    "#                 writegrp.attrs.update(systemgrp.attrs)\n",
    "#                 try:\n",
    "#                     writefile.copy(systemgrp['inputs'], writegrp)\n",
    "#                 except RuntimeError:\n",
    "#                     pass\n",
    "#                 outgrp = writegrp.require_group('outputs')\n",
    "#                 for dname, dset in readout.items():\n",
    "#                     if dname in outgrp:\n",
    "#                         continue\n",
    "#                     if not dset:\n",
    "#                         continue\n",
    "#                     try:\n",
    "#                         oset = outgrp.create_dataset(\n",
    "#                             dname,\n",
    "#                             data = dset[()],\n",
    "#                             chunks = dset.shape\n",
    "#                             )\n",
    "#                     except OSError:\n",
    "#                         try:\n",
    "#                             oset = outgrp.create_dataset(\n",
    "#                                 dname,\n",
    "#                                 data = (sub := dset[:-10]),\n",
    "#                                 chunks = sub.shape\n",
    "#                                 )\n",
    "#                         except OSError:\n",
    "#                             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         for i, (key, grp) in enumerate(readfile.items()):\n",
    "#             if not i % 1000:\n",
    "#                 print('.')\n",
    "#             try:\n",
    "#                 observees[key] = grp['inputs'].attrs['observee'][7:]\n",
    "#             except KeyError:\n",
    "#                 continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit(key, grp):\n",
    "    try:\n",
    "        if not grp.attrs['supertype'] == '_string_Observer':\n",
    "            continue\n",
    "    except KeyError:\n",
    "        return\n",
    "    try:\n",
    "        systemid = grp['inputs']['observee'][7:]\n",
    "    except KeyError:\n",
    "        return\n",
    "    systemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, (key, grp) in enumerate(readfile.items()):\n",
    "        grpkeys = grp.keys()\n",
    "        try:\n",
    "            if not grp.attrs['supertype'] == '_string_Observer':\n",
    "                continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if not i % 1000:\n",
    "            print(key)\n",
    "        try:\n",
    "            readout = grp['outputs']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        hashID = grp.attrs['hashID'][8:]\n",
    "        writegrp = writefile.require_group(hashID)\n",
    "        systemgrp = readfile[hashID]\n",
    "        writegrp.attrs.update(systemgrp.attrs)\n",
    "        try:\n",
    "            writefile.copy(systemgrp['inputs'], writegrp)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        outgrp = writegrp.require_group('outputs')\n",
    "        for dname, dset in readout.items():\n",
    "            if dname in outgrp:\n",
    "                continue\n",
    "            if not dset:\n",
    "                continue\n",
    "            try:\n",
    "                oset = outgrp.create_dataset(\n",
    "                    dname,\n",
    "                    data = dset[()],\n",
    "                    chunks = dset.shape\n",
    "                    )\n",
    "            except OSError:\n",
    "                try:\n",
    "                    oset = outgrp.create_dataset(\n",
    "                        dname,\n",
    "                        data = (sub := dset[:-10]),\n",
    "                        chunks = sub.shape\n",
    "                        )\n",
    "                except OSError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ahead-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/morpheus/workspace/mount/data/charon5/linear2.frm'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frmPaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "designed-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('inputs', <HDF5 group \"/xoosftzii-skorhgleuv/inputs\" (0 members)>), ('observee', <HDF5 group \"/xoosftzii-skorhgleuv/observee\" (6 members)>)]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(frmPaths[0], mode = 'r') as h5file:\n",
    "    print(list(h5file['xoosftzii-skorhgleuv'].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dynamic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = frmPaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "meaningful-permission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.7 ns ± 0.0456 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bool(1 % 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "piano-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function write_direct in module h5py._hl.dataset:\n",
      "\n",
      "write_direct(self, source, source_sel=None, dest_sel=None)\n",
      "    Write data directly to HDF5 from a NumPy array.\n",
      "    \n",
      "    The source array must be C-contiguous.  Selections must be\n",
      "    the output of numpy.s_[<args>].\n",
      "    \n",
      "    Broadcasting is supported for simple indexing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h5py.Dataset.write_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "quarterly-manner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function create_dataset in module h5py._hl.group:\n",
      "\n",
      "create_dataset(self, name, shape=None, dtype=None, data=None, **kwds)\n",
      "    Create a new HDF5 dataset\n",
      "    \n",
      "    name\n",
      "        Name of the dataset (absolute or relative).  Provide None to make\n",
      "        an anonymous dataset.\n",
      "    shape\n",
      "        Dataset shape.  Use \"()\" for scalar datasets.  Required if \"data\"\n",
      "        isn't provided.\n",
      "    dtype\n",
      "        Numpy dtype or string.  If omitted, dtype('f') will be used.\n",
      "        Required if \"data\" isn't provided; otherwise, overrides data\n",
      "        array's dtype.\n",
      "    data\n",
      "        Provide data to initialize the dataset.  If used, you can omit\n",
      "        shape and dtype arguments.\n",
      "    \n",
      "    Keyword-only arguments:\n",
      "    \n",
      "    chunks\n",
      "        (Tuple or int) Chunk shape, or True to enable auto-chunking. Integers can\n",
      "        be used for 1D shape.\n",
      "    \n",
      "    maxshape\n",
      "        (Tuple or int) Make the dataset resizable up to this shape. Use None for\n",
      "        axes you want to be unlimited. Integers can be used for 1D shape.\n",
      "    compression\n",
      "        (String or int) Compression strategy.  Legal values are 'gzip',\n",
      "        'szip', 'lzf'.  If an integer in range(10), this indicates gzip\n",
      "        compression level. Otherwise, an integer indicates the number of a\n",
      "        dynamically loaded compression filter.\n",
      "    compression_opts\n",
      "        Compression settings.  This is an integer for gzip, 2-tuple for\n",
      "        szip, etc. If specifying a dynamically loaded compression filter\n",
      "        number, this must be a tuple of values.\n",
      "    scaleoffset\n",
      "        (Integer) Enable scale/offset filter for (usually) lossy\n",
      "        compression of integer or floating-point data. For integer\n",
      "        data, the value of scaleoffset is the number of bits to\n",
      "        retain (pass 0 to let HDF5 determine the minimum number of\n",
      "        bits necessary for lossless compression). For floating point\n",
      "        data, scaleoffset is the number of digits after the decimal\n",
      "        place to retain; stored values thus have absolute error\n",
      "        less than 0.5*10**(-scaleoffset).\n",
      "    shuffle\n",
      "        (T/F) Enable shuffle filter.\n",
      "    fletcher32\n",
      "        (T/F) Enable fletcher32 error detection. Not permitted in\n",
      "        conjunction with the scale/offset filter.\n",
      "    fillvalue\n",
      "        (Scalar) Use this value for uninitialized parts of the dataset.\n",
      "    track_times\n",
      "        (T/F) Enable dataset creation timestamps.\n",
      "    track_order\n",
      "        (T/F) Track attribute creation order if True. If omitted use\n",
      "        global default h5.get_config().track_order.\n",
      "    external\n",
      "        (Iterable of tuples) Sets the external storage property, thus\n",
      "        designating that the dataset will be stored in one or more\n",
      "        non-HDF5 files external to the HDF5 file.  Adds each tuple\n",
      "        of (name, offset, size) to the dataset's list of external files.\n",
      "        Each name must be a str, bytes, or os.PathLike; each offset and\n",
      "        size, an integer.  If only a name is given instead of an iterable\n",
      "        of tuples, it is equivalent to [(name, 0, h5py.h5f.UNLIMITED)].\n",
      "    allow_unknown_filter\n",
      "        (T/F) Do not check that the requested filter is available for use.\n",
      "        This should only be used with ``write_direct_chunk``, where the caller\n",
      "        compresses the data before handing it to h5py.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h5py.Group.create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "interim-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_direct in module h5py._hl.dataset:\n",
      "\n",
      "read_direct(self, dest, source_sel=None, dest_sel=None)\n",
      "    Read data directly from HDF5 into an existing NumPy array.\n",
      "    \n",
      "    The destination array must be C-contiguous and writable.\n",
      "    Selections must be the output of numpy.s_[<args>].\n",
      "    \n",
      "    Broadcasting is supported for simple indexing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h5py.Dataset.read_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "robust-delay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function copy in module h5py._hl.group:\n",
      "\n",
      "copy(self, source, dest, name=None, shallow=False, expand_soft=False, expand_external=False, expand_refs=False, without_attrs=False)\n",
      "    Copy an object or group.\n",
      "    \n",
      "     The source can be a path, Group, Dataset, or Datatype object.  The\n",
      "     destination can be either a path or a Group object.  The source and\n",
      "     destinations need not be in the same file.\n",
      "    \n",
      "     If the source is a Group object, all objects contained in that group\n",
      "     will be copied recursively.\n",
      "    \n",
      "     When the destination is a Group object, by default the target will\n",
      "     be created in that group with its current name (basename of obj.name).\n",
      "     You can override that by setting \"name\" to a string.\n",
      "    \n",
      "     There are various options which all default to \"False\":\n",
      "    \n",
      "      - shallow: copy only immediate members of a group.\n",
      "    \n",
      "      - expand_soft: expand soft links into new objects.\n",
      "    \n",
      "      - expand_external: expand external links into new objects.\n",
      "    \n",
      "      - expand_refs: copy objects that are pointed to by references.\n",
      "    \n",
      "      - without_attrs: copy object without copying attributes.\n",
      "    \n",
      "    Example:\n",
      "    \n",
      "     >>> f = File('myfile.hdf5', 'w')\n",
      "     >>> f.create_group(\"MyGroup\")\n",
      "     >>> list(f.keys())\n",
      "     ['MyGroup']\n",
      "     >>> f.copy('MyGroup', 'MyCopy')\n",
      "     >>> list(f.keys())\n",
      "     ['MyGroup', 'MyCopy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(h5py.Group.copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "continued-check",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "copy() missing 3 required positional arguments: 'self', 'source', and 'dest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3c4331d2420a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: copy() missing 3 required positional arguments: 'self', 'source', and 'dest'"
     ]
    }
   ],
   "source": [
    "ah5py.File.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "silver-wrestling",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'h5py' has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3ea8dc9c1da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'h5py' has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "h5py.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "continent-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aabeapleozh-xeewrspueph\n",
      "aabloieoblua-kronbriung\n",
      "aabruoqoosp-vaodwuezhio\n",
      "aacaewapr-eikaaeaswoo\n",
      "aachianeakw-iugsfaopl\n",
      "aachoeheufl-hiiprsnoifl\n",
      "aacoeceath-klaitrskui\n",
      "aaflaughoth-kweoytheiph\n",
      "aafloaweef-ngourhgluakr\n",
      "aafoauofa-priokwich\n",
      "aagaispoekl-kluosfsmoodr\n",
      "aaghuuchoatz-eiglaismeosh\n",
      "aaguokiis-iusfeeatsei\n",
      "aaheiuozhea-iuhuadraath\n",
      "aahooisnia-dwuayweedw\n",
      "aajasfiisn-droiroupreo\n",
      "aakouwiing-iegloachaoz\n",
      "aakwoirhui-aefaosoikr\n",
      "aaliapsou-spaiphkoub\n",
      "aamiograo-uitruogreig\n",
      "aaphaaipa-freuchrhaesk\n",
      "aaphoezhaiq-xautzgrac\n",
      "aapleakeogl-stuazhfreudr\n",
      "aapluaepsoi-ooslaitsain\n",
      "aapseithoej-skeigrmoaz\n",
      "aaqublioth-iawraocad\n",
      "aarhaabrim-dooblzoekr\n",
      "aarheegliesm-spoatghausp\n",
      "aarhoosael-snouwruobei\n",
      "aascauaoglio-aikeuuigoe\n",
      "aaseaeyeu-blaouichuo\n",
      "aasfeoaakroe-uifroiatria\n",
      "aashagretw-smaofiaraa\n",
      "aasieathai-matsxuatz\n",
      "aaskeonou-fruashtruukr\n",
      "aaskuedreoq-ngoosrood\n",
      "aasliouetwiu-huovoaskuo\n",
      "aasmaaaigu-leeshciudr\n",
      "aasmaouujao-phedrrhaodw\n",
      "aaspeostu-xeigloekwie\n",
      "aastatsau-waedoazuo\n",
      "aastoeghiph-euhaghoe\n",
      "aasuijiap-euploabeetw\n",
      "aasweulaokw-tsoekudwa\n",
      "aataaswiotr-ceahakwio\n",
      "aataheaj-plolpsoesp\n",
      "aatheouigreo-iprouskeich\n",
      "aathuoaetoa-weingheun\n",
      "aatriukleegh-aeswaospeoq\n",
      "aatriuskiosh-kiobraewrie\n",
      "aatseaduosp-tzaugrtwapl\n",
      "aatwuoscuuch-ootsuewaitw\n",
      "aatzoioofrou-eosfeueosmua\n",
      "aaveismiom-seuslbruuq\n",
      "aaweauvui-briawrurhii\n",
      "aawiaauflii-oudraepriits\n",
      "aaxaeuibae-kweazhueguo\n",
      "aaxausnuef-oisniepluast\n",
      "aayiaoepsue-peiphaifli\n",
      "aayiuuusleo-oevaisfoing\n",
      "aazhodween-shepraesiu\n",
      "aazuusmeitw-iorhaatraips\n",
      "abauafloa-oiwiopruu\n",
      "abeuablae-uaspifliagr\n",
      "abrauiti-aubluiyuib\n",
      "abrooowu-tsuabgruetw\n",
      "adwanabr-bluoscueyie\n",
      "adwiesfuokw-speoskaeru\n",
      "aebijeing-ekaacuikl\n",
      "aeblieecai-eislaosfoas\n",
      "aebluaesteo-kreigrwrafr\n",
      "aebroethadw-kwaahiarhau\n",
      "aedoouutziu-uokwieute\n",
      "aeduapsoest-nguenaisnie\n",
      "aedweproedr-iisnetwaebl\n",
      "aefeikwost-troitwpsaich\n",
      "aeflauchoan-feplpaebl\n",
      "aefleeeedwo-wueshskoj\n",
      "aefliaaokri-igheothieg\n",
      "aefrkwaisw-uuzhiimausp\n",
      "aefroasfiey-daarwroub\n",
      "aeghoeiabrii-eijengom\n",
      "aegluuliey-ziatokraa\n",
      "aegreaheesw-flautsteasf\n",
      "aehaaeuqua-kwoiruasleu\n",
      "aeheipsiokl-uuglaoaaze\n",
      "aekaeloufr-jiadruingau\n",
      "aekiebrizh-iuzhuaaetzeu\n",
      "aeklufliusc-smeuwuethoi\n",
      "aekoghaits-aatseejoeh\n",
      "aekraoautweu-iopsouxeup\n",
      "aekraosfoesp-phuasfaothai\n",
      "aekwaeoaxei-krakretweo\n",
      "aekwaerhaosl-chairhaisfoe\n",
      "aemengiesp-hoewuasmoe\n",
      "aengeaiochou-fraepjauf\n",
      "aengeukluiz-sceotzeekree\n",
      "aeniuousluu-ouprefroesm\n",
      "aeplaoiikrai-eochouaaskoe\n",
      "aepliidwuafl-flaewkloik\n",
      "aepliujiikr-eospoedwios\n",
      "aepriasoon-iusiikroasf\n",
      "aepsoeuesfa-ghiuzflaaq\n",
      "aeqeatruoq-scokuublei\n",
      "aeriuesnoe-psooblpliugh\n",
      "aesciajaur-suaxpsoafr\n",
      "aesciiquakr-oaplitiesn\n",
      "aeshoubuukr-piikrplaisw\n",
      "aeskaeiubroi-wroessnuut\n",
      "aeskostiasm-feobaiyiu\n",
      "aeslaiaevoe-psuiflchauy\n",
      "aeslieioflo-ruupsuzh\n",
      "aesloogiesm-uestipsoof\n",
      "aesloouwei-rhuicyuiph\n",
      "aesmaeuafroo-oepoatzoen\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4e7b0ab349f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mhashID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mwritegrp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwritefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mreadfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwritegrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mwritefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhashID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwritegrp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, source, dest, name, shallow, expand_soft, expand_external, expand_refs, without_attrs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0mcopypl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             h5o.copy(source.id, self._e(source_path), dest.id, self._e(dest_path),\n\u001b[0m\u001b[1;32m    522\u001b[0m                      copypl, base.dlcpl)\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with h5py.File('temp.frm', mode = 'w') as writefile:\n",
    "    with h5py.File(os.path.join(testpath), mode = 'r') as readfile:\n",
    "        for i, (key, grp) in enumerate(readfile.items()):\n",
    "            if i > 1000:\n",
    "                print('.')\n",
    "            grpkeys = grp.keys()\n",
    "            if not 'observee' in grpkeys:\n",
    "                continue\n",
    "            hashID = grp.attrs['hashID'][8:]\n",
    "            writegrp = writefile.require_group(hashID)\n",
    "            writefile.copy(readfile[hashID]['inputs'], writegrp)\n",
    "            readfile.copy(grp['outputs'], writegrp, name = grp.attrs['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adult-smooth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20023"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.Fil(os.path.join(datadir, 'out.frm'), mode = 'r') as writefile:\n",
    "    with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader('mergedcopy', datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = []\n",
    "def visitprint(name):\n",
    "    global i\n",
    "    global out\n",
    "    i += 1\n",
    "    if i > 100:\n",
    "        return True\n",
    "    out.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "#     readfile.visit(visitprint)\n",
    "    readfile.visit(out.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "    readfile.id.links.iterate(links.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "with h5py.File(os.path.join(datadir, 'merged.frm'), mode = 'r') as readfile:\n",
    "    links = deque()\n",
    "    readfile.id.links.iterate(links.append)\n",
    "    subpaths = deque()\n",
    "    for i, link in enumerate(links):\n",
    "        if not i % 1000:\n",
    "            print('.')\n",
    "        subpaths.clear()\n",
    "        readfile[link].visit(subpaths.append)\n",
    "        if 'observee' in subpaths:\n",
    "            target = datasets.setdefault(\n",
    "                readfile[link]['observee'].attrs['hashID'][8:],\n",
    "                deque()\n",
    "                )\n",
    "            linkmaker = lambda x: target.append(os.path.join(link.decode(), 'outputs', x))\n",
    "            readfile[link]['outputs'].visit(linkmaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-dominican",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from collections import deque\n",
    "\n",
    "import h5py\n",
    "\n",
    "from aliases import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "osjoin = os.path.join\n",
    "def get_framepaths(datadir):\n",
    "    frmPaths = []\n",
    "    subDirs = [\n",
    "        p for p in (osjoin(datadir, n) for n in os.listdir(datadir))\n",
    "            if os.path.isdir(p)\n",
    "        ]\n",
    "    for subDir in subDirs:\n",
    "        frmPaths.extend(\n",
    "            osjoin(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "            )\n",
    "    return frmPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename('/home/morpheus/workspace/mount/data/charon5/linear2.frm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "osrel = os.path.relpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "osrel('/home/morpheus/workspace/mount/data/charon5/linear2.frm', datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_framepaths(datadir).index('/home/morpheus/workspace/mount/data/pluto1/.frm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(datadir, 'pluto1', 'linear2.frm'), mode = 'r') as h5file:\n",
    "    print(h5file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-price",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "frmPaths = []\n",
    "subDirs = [\n",
    "    p for p in (os.path.join(datadir, n) for n in os.listdir(datadir))\n",
    "        if os.path.isdir(p)\n",
    "    ]\n",
    "for subDir in subDirs:\n",
    "    frmPaths.extend(\n",
    "        os.path.join(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.Group.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.ExternalLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_string_foo'[8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "observees = dict()\n",
    "\n",
    "frmPath = frmPaths[0]\n",
    "with h5py.File('temp.frm', mode = 'w') as writefile:\n",
    "    with h5py.File(frmPath, mode = 'r') as readfile:\n",
    "        for i, (key, grp) in enumerate(readfile.items()):\n",
    "            if not i % 1000:\n",
    "                print('.')\n",
    "            try:\n",
    "                styp = grp.attrs['supertype'][8:]\n",
    "                if styp == 'System':\n",
    "                    wgrp = writefile.require_group(key)\n",
    "                    wgrp.attrs.update(grp.attrs)\n",
    "                    wgrp['inputs'] = h5py.ExternalLink(frmPath, os.path.join(key, 'inputs'))\n",
    "                elif styp == 'Observer':\n",
    "                    typ = grp.attrs['type'][8:]\n",
    "                    wgrp = writefile.require_group(grp['inputs'].attrs['observee'][7:])\n",
    "                    okey = typ.lower()\n",
    "                    if okey in wgrp:\n",
    "                        if len(wgrp[okey]['count']) > len(grp['outputs']['count']):\n",
    "                            continue\n",
    "                    wgrp[okey] = h5py.ExternalLink(frmPath, os.path.join(key, 'outputs'))\n",
    "            except (KeyError, RuntimeError):\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = h5py.File('temp.frm', mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile['aabrspuugh-eistiopoov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with h5py.File('temp.frm', mode = 'r') as h5file:\n",
    "    print(len(h5file))\n",
    "    out = h5file['aabrspuugh-eistiopoov']['thermo']['Nu'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not __name__ == '__main__':\n",
    "#     raise RuntimeError\n",
    "\n",
    "# import os\n",
    "# from collections import deque\n",
    "\n",
    "# import h5py\n",
    "\n",
    "# from aliases import *\n",
    "\n",
    "# frmPaths = []\n",
    "# subDirs = [\n",
    "#     p for p in (os.path.join(datadir, n) for n in os.listdir(datadir))\n",
    "#         if os.path.isdir(p)\n",
    "#     ]\n",
    "# for subDir in subDirs:\n",
    "#     frmPaths.extend(\n",
    "#         os.path.join(subDir, n) for n in os.listdir(subDir) if (n.endswith('.frm'))\n",
    "#         )\n",
    "\n",
    "# with h5py.File(os.path.join(datadir, 'allout.frm'), mode = 'w') as writefile:\n",
    "#     for frmPath in frmPaths:\n",
    "#         print('-' * 10 + frmPath + '-' * 10)\n",
    "#         with h5py.File(frmPath, mode = 'r') as readfile:\n",
    "#             for i, (key, grp) in enumerate(readfile.items()):\n",
    "#                 grpkeys = grp.keys()\n",
    "#                 try:\n",
    "#                     if not grp.attrs['supertype'] == '_string_Observer':\n",
    "#                         continue\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#                 if not i % 1000:\n",
    "#                     print(key)\n",
    "#                 try:\n",
    "#                     readout = grp['outputs']\n",
    "#                 except KeyError:\n",
    "#                     continue\n",
    "#                 hashID = grp.attrs['hashID'][8:]\n",
    "#                 writegrp = writefile.require_group(hashID)\n",
    "#                 systemgrp = readfile[hashID]\n",
    "#                 writegrp.attrs.update(systemgrp.attrs)\n",
    "#                 try:\n",
    "#                     writefile.copy(systemgrp['inputs'], writegrp)\n",
    "#                 except RuntimeError:\n",
    "#                     pass\n",
    "#                 outgrp = writegrp.require_group('outputs')\n",
    "#                 for dname, dset in readout.items():\n",
    "#                     if dname in outgrp:\n",
    "#                         continue\n",
    "#                     if not dset:\n",
    "#                         continue\n",
    "#                     try:\n",
    "#                         oset = outgrp.create_dataset(\n",
    "#                             dname,\n",
    "#                             data = dset[()],\n",
    "#                             chunks = dset.shape\n",
    "#                             )\n",
    "#                     except OSError:\n",
    "#                         try:\n",
    "#                             oset = outgrp.create_dataset(\n",
    "#                                 dname,\n",
    "#                                 data = (sub := dset[:-10]),\n",
    "#                                 chunks = sub.shape\n",
    "#                                 )\n",
    "#                         except OSError:\n",
    "#                             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#         for i, (key, grp) in enumerate(readfile.items()):\n",
    "#             if not i % 1000:\n",
    "#                 print('.')\n",
    "#             try:\n",
    "#                 observees[key] = grp['inputs'].attrs['observee'][7:]\n",
    "#             except KeyError:\n",
    "#                 continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visit(key, grp):\n",
    "    try:\n",
    "        if not grp.attrs['supertype'] == '_string_Observer':\n",
    "            continue\n",
    "    except KeyError:\n",
    "        return\n",
    "    try:\n",
    "        systemid = grp['inputs']['observee'][7:]\n",
    "    except KeyError:\n",
    "        return\n",
    "    systemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for i, (key, grp) in enumerate(readfile.items()):\n",
    "        grpkeys = grp.keys()\n",
    "        try:\n",
    "            if not grp.attrs['supertype'] == '_string_Observer':\n",
    "                continue\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if not i % 1000:\n",
    "            print(key)\n",
    "        try:\n",
    "            readout = grp['outputs']\n",
    "        except KeyError:\n",
    "            continue\n",
    "        hashID = grp.attrs['hashID'][8:]\n",
    "        writegrp = writefile.require_group(hashID)\n",
    "        systemgrp = readfile[hashID]\n",
    "        writegrp.attrs.update(systemgrp.attrs)\n",
    "        try:\n",
    "            writefile.copy(systemgrp['inputs'], writegrp)\n",
    "        except RuntimeError:\n",
    "            pass\n",
    "        outgrp = writegrp.require_group('outputs')\n",
    "        for dname, dset in readout.items():\n",
    "            if dname in outgrp:\n",
    "                continue\n",
    "            if not dset:\n",
    "                continue\n",
    "            try:\n",
    "                oset = outgrp.create_dataset(\n",
    "                    dname,\n",
    "                    data = dset[()],\n",
    "                    chunks = dset.shape\n",
    "                    )\n",
    "            except OSError:\n",
    "                try:\n",
    "                    oset = outgrp.create_dataset(\n",
    "                        dname,\n",
    "                        data = (sub := dset[:-10]),\n",
    "                        chunks = sub.shape\n",
    "                        )\n",
    "                except OSError:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "frmPaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(frmPaths[0], mode = 'r') as h5file:\n",
    "    print(list(h5file['xoosftzii-skorhgleuv'].items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = frmPaths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "bool(1 % 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h5py.Dataset.write_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h5py.Group.create_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h5py.Dataset.read_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(h5py.Group.copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "ah5py.File.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5py.copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('temp.frm', mode = 'w') as writefile:\n",
    "    with h5py.File(os.path.join(testpath), mode = 'r') as readfile:\n",
    "        for i, (key, grp) in enumerate(readfile.items()):\n",
    "            if i > 1000:\n",
    "                print('.')\n",
    "            grpkeys = grp.keys()\n",
    "            if not 'observee' in grpkeys:\n",
    "                continue\n",
    "            hashID = grp.attrs['hashID'][8:]\n",
    "            writegrp = writefile.require_group(hashID)\n",
    "            writefile.copy(readfile[hashID]['inputs'], writegrp)\n",
    "            readfile.copy(grp['outputs'], writegrp, name = grp.attrs['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.Fil(os.path.join(datadir, 'out.frm'), mode = 'r') as writefile:\n",
    "    with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader('mergedcopy', datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = []\n",
    "def visitprint(name):\n",
    "    global i\n",
    "    global out\n",
    "    i += 1\n",
    "    if i > 100:\n",
    "        return True\n",
    "    out.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "#     readfile.visit(visitprint)\n",
    "    readfile.visit(out.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "with h5py.File(os.path.join(datadir, 'mergedcopy.frm'), mode = 'r') as readfile:\n",
    "    readfile.id.links.iterate(links.append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "with h5py.File(os.path.join(datadir, 'merged.frm'), mode = 'r') as readfile:\n",
    "    links = deque()\n",
    "    readfile.id.links.iterate(links.append)\n",
    "    subpaths = deque()\n",
    "    for i, link in enumerate(links):\n",
    "        if not i % 1000:\n",
    "            print('.')\n",
    "        subpaths.clear()\n",
    "        readfile[link].visit(subpaths.append)\n",
    "        if 'observee' in subpaths:\n",
    "            target = datasets.setdefault(\n",
    "                readfile[link]['observee'].attrs['hashID'][8:],\n",
    "                deque()\n",
    "                )\n",
    "            linkmaker = lambda x: target.append(os.path.join(link.decode(), 'outputs', x))\n",
    "            readfile[link]['outputs'].visit(linkmaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-dominican",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
